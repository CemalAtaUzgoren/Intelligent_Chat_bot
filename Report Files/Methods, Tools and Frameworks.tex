\section{Methods, Tools and Frameworks}
% In this section, you should describe the methods, programming languages, packages, tools and framework you plan to use.
% for this report, you can list some you have identified and intend to use.
% No need to give any details.     

The primary programming languages used for this project are Python and JavaScript. \textit{PostgresDB} was initially considered for the KnowledgeBase, however the project has found sufficient success using local csv files as an alternative to databases.

\paragraph{Programming Languages:} Python \& JavaScript.
\paragraph{GUI development:} HTML \& CSS.
\paragraph{Packages:} NLP, NLTK locationtagger\citep{NLTK}, Spacy's ``en\_core\_web\_lg model''. For matching regex patterns: Selenium, requests, html-requests, BeautifulSoup, Minidom, lxml, urllib3 etc\dots %for web scraping mechanism. 
\paragraph{KnowledgeBase and Engine:} CSV \& JSON.\\
\noindent
\\Below is the in detail description of the tools and frameworks used for each component of the project:-
\subsection{Chatbot GUI}
\begin{itemize}
    \item Graphical User Interface: GUI development using JS, NodeJS, HTML, CSS.
    \item Voice Commands: Text-to-Speech \& Speech-To-Text recognition using APIs such as webkitSpeechRecognition, SpeechRecognition etc. 
\end{itemize}
\subsection{Web Scraping}
\begin{itemize}
    \item Selenium: This library was used to scrape data from the websites who doesn't provide any API to extract data in form of response.
    \item Requests: This module was used to extract data via HTTP/HTTPS requests.
    \item BeautifulSoup: This library was used to scrape websites HTML elements to fetch data.
\end{itemize}
\subsection{Chatbot Conversation - NLP}\label{Sec: Methods/NLP}
    \begin{itemize}
        \item Spacy: This library was used for natural language processing specifically for named-entity recognition (NER).
        \item Nltk: This toolkit was used along with spaCy for NLP.
        \item Fuzzywuzzy: This library was used to determine closes matches in the user input to extract relevant information.
        \item Experta: This library was used for building expert systems to provide suitable answers to the user.
    \end{itemize}
\subsection{Regression Model Prediction}
\paragraph{Models Utilised}
A variety of commonly implemented regression models were employed to predict the arrival at Norwich from the departure from London Liverpool Street. These models incline:
\begin{itemize}
    \item Multi Layer Perception (MLP) Regression: the sklearn.neural\_network library was used to build a simple MLP model \citep{scikit-learn}.
    \item K-Nearest Neighbors (KNN) Regression: the sklearn.neighbors library was used to build and tune a K-Nearest Neighbors model \citep{scikit-learn}.
    \item XGBoost (XGB) Regression: the XGBoost model from \cite{chen2016xgboost} was implemented.
    \item Random Forest (RF) Regression: the sklearn.ensemble library was used to build and tune a Random Forest model \citep{scikit-learn}.
    \item Linear Regression: the sklearn.linear\_model library was used to implement a Linear Regression model \citep{scikit-learn}.
    \item Huber Regressor: the sklearn.linear\_model library was used to implement a Huber Regressor model \citep{scikit-learn}.
    \item Lasso Regressor: the sklearn.linear\_model library was used to implement a Lasso Regressor model \citep{scikit-learn}.
    \item Stochastic Gradient Descent Regressor: the sklearn.linear\_model library was used to implement a Stochastic Gradient Descent Regression model \citep{scikit-learn}.
\end{itemize}

\paragraph{Metrics and performance evaluation}\label{Sec: Regression Metrics & performance}
During the training process each model was fitted to 80\% of the dataset while 20\% was employed as validation data. Each model will predict the arrival time at Norwich based on the values in the training dataset.

    \begin{itemize}
        \item NumPy: This was used for data manipulation and numerical calculate \citep{harris2020array}.
        \item Pandas: This was used for data storage inside dataframes along with dataframe manipulation tasks \citep{reback2020pandas}.
        \item sklearn: This library was used for data preprocessing and model metrics \citep{scikit-learn}.
        \item Seaborn and MatPlotlib: was used to generate visual representation of the data \citep{Waskom2021},\citep{Hunter:2007}.
    \end{itemize} 
 
\subsection{Development Framework}
The following sections outline and describe the current efforts and developments made towards achieving the aims and objectives described in Section \ref{Sec: Aim and Objs}.

\subsubsection{Flowchart}
Figure \ref{Fig: Flowchart} details a high-level flow chart of the chatbot when the user requests a train ticket. 

\subsubsection{Use Case and Sequence Diagrams}
Figure \ref{Fig: use case whole system} describes a use case diagram of the whole system. Also the general logic of the chatbot constructed by following the algorithms of the sequence diagrams which are stated in figure \ref{}, \ref{}, and \ref{} for each of the parts.

% \subsubsection{Sequence Diagrams}\label{Sec: Sequence Diagrams}
% The following sections describes the sequence diagrams for each mechanism the acheive the goals outlined in Section \ref{Sec: Aim and Objs}.