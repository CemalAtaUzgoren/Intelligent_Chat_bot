\section{Analysis of Related Work}\label{sec: related works}
This section will outline two examples of large language models (LLM) currently available for free and evaluate their performance with regards with the tasks relevant to this project. These include:
\begin{enumerate}
    \item Accurately searching the live arrival and departure of train times
    \item Offering the ability to provide the user with a URL link to purchase tickets extracted
    \item Predicting arrival train times when a train is delayed at a specific station during a journey
    \item Advising on the correct protocol when faced with contingencies
\end{enumerate}
\subsection{Microsoft Bing Co-Pilot}\label{Sec: Review Bing co-pilot}
The Microsoft Bing co-pilot is currently developed using the GPT-4.0 LLM manufactured by OpenAI \citep{bing-gpt4}. Unlike the Chat-GPT LLM, Bing co-pilot has the ability to extract information from the internet and utilise it in a conversional response. Due to this unique ability, it has become a powerful search engine alternative. The following sections will outline Bing co-pilot's ability to complete the tasks outlined in Section \ref{Sec: Aim and Objs}.

\subsubsection{Ability To Extract Live Train Ticket Prices}
This model demonstrates great ability for conversation however the main objective to achieve is to search and extract live train times of a given journey. When the model is prompted with the request ``find me the cheapest train ticket from London Liverpool Street to Norwich?'' it returned a vague response with no exact value or information. Figure \ref{Fig: example of bing co-pilot} demonstrates the response given which states a ``starting price of £10'' for the journey and also includes hyper links to online services to purchases train tickets.\vspace{0.5cm}

\noindent
Upon further inspection the quote of a ``£10 stating price'' was extracted from an online advertisements created by Trainline. A second attempt to request train tickets was explored with the following prompt ``Please can you find me the cheapest train ticket from London Liverpool Street to Norwich for Monday 20th at 12:00?''. Figure \ref{Fig: example of bing co-pilot revised} demonstrates a similar result to the previous prompt with a quoted starting price of £10. The hyperlink provided points to the TrainLine online service, the service displays a month calendar with the cheapest available ticket per day. Figure \ref{Fig: train-line booking results from bing} shows three days which match the quote of ``£10'' for the the cheapest ticket. Unfortunately, this response and suggested price is inaccurate as it is for days Wednesday 8th, Friday 7th and Saturday 8th, not Monday 20th as requested in the prompt. Moreover, accessing the particular date which quotes tickets in access of £10 is vacant of such prices. This leads to the assumption a singular ticket could cost £10 but would be at less that desirable off-peak times.

\subsubsection{Ability to Predict Train Delays}\label{Sec: Co-pilot delay prediction}
As per the secondary task described in Section \ref{Sec: Aim and Objs}, the LLM was prompted to predict the delayed arrival of a train journey between London Liverpool Street and Norwich when delayed at Ipswich. The following prompt ``I am currently on a train as Ipswitch during a journey from London Liverpool Street to Norwich. I left London at 12:00, the train was planned to depart from Ipswich at 13:07 but we are now departing at 13:15. What time would I arrive at Norwich?'' was given. The response was an inaccurate attempt as the predicted arrival time at Norwich was 14:56 when the true planned arrival time was 13:46. %As the prompted departure time from Ipswich was 8 minutes delayed which led the predicted arrival time to be one 1 hour and 10 minutes past the planned arrival time at Norwich, 
Figure \ref{Fig: bing copilot delay response} shows the response in full. Using our regression model to predict the arrival time using this scenario, the predicated arrival time was ``13:52'' which was 6 minutes later than the planned time. 

\subsubsection{Ability to handle and advise contingencies}\label{Sec: co-pilot contingencies}
As per the final task, the chatbot should be able to accurately advise a staff member on the protocol when faced with a contingency. The scenario referenced when interacting with the chat bot is a ``Full Line Blockage Between Ipswich and Stowmarket''. The prompt used was ``I am a train conductor on a train between Ipswich and Stowmarket. Unfortunately there is a full line blockage contingency. What should we do?''. Figure \ref{Fig: bing copilot contingency} shows the response, review of the response shows general safety advisory steps such as ensuring passenger safety, contacting and communicating with the rail control centre to report the blockage. This advice can be acceptable but shows no specific form of action.

\subsubsection{Conclusion}
The model can extract inaccurate information which appears to be a extracts from online advertisements and is dissimilar to the requirements found in the prompt. When asked to predict the delayed arrival at a station it gave an accurate description of the journey distance and travelling time but in despite of this, it gave an inaccurate arrival time. Overall the model shows potential for achieving the desired results. However due to the limitations of being a ``smart'' search engine, it relies on the collected internet sources to be accurate. %The LLM itself is unable to competently achieve the aims without the source material being accurate first.
With this key information the model cannot be confidently used to acquire train tickets or predict the delayed arrival times. When asked to advise on handling contingencies the model gave general advice without any specific instructions. The same prompt was given to our model which returned detailed instructions as shown in Figure \ref{Fig: Our-bot contingency}. A conclusion was drawn that within the given restrictions and goals, our chatbot was superior.


\subsection{Phi-3-mini}
The Microsoft developed MML Phi-3-mini boasts a moderate 3.8 billion parameters which were trained on 3.3 trillion tokens. It uses a transformer decoder architecture and limits itself with a default context length of 4$K$. However, with the introduction of LongRope, this limit extends to 128$K$, this extended model is named Phi-3-mini-128k. %It is currently open source and built on top of the Llama-2 family and uses the same tokeniser with vocabulary size of 32064. The model utilises the improvements from using the Tiktoken tokeniser with a vocabulary size of 100352. The results of this are... TBF As the model can be quantised to 4-bits, the required memory for the model to efficiently operate is $≈$ 1.8GB.
\subsubsection{Ability To Extract Live Train Ticket Prices}
When the model is prompted to fetch and present live train times, it will notify the user that the model is unable to get these values. Further testing shows that the model does not have access to the internet and thus live data. Figure \ref{Fig: Phi-3-mini train times} shows the response of the model. With this information no further testing was given.

\subsubsection{Ability to Predict Train Delays}
Similar to Section \ref{Sec: Co-pilot delay prediction} the chatbot was asked ``I am currently on a train as Ipswitch during a journey from London Liverpool Street to Norwich. I left London at 12:00, the train was planned to depart from Ipswich at 13:07 but we are now departing at 13:15. What time would I arrive at Norwich?''. The response shown in Figure \ref{Fig: Phi-3-mini dealy prediction} describes the train journey from Ipswich to Norwich as a 2 hour journey. However the TrainLine service, which was used as a reference, describes the journey as being 39 minutes as shown in Figure \ref{Fig: Trainline example LDN to NRW}. Both models have inaccurately estimated the journey time between these two stations.

\subsubsection{Ability to handle and advise contingencies}
Similar to Section \ref{Sec: co-pilot contingencies} the chatbot was asked how to handle a full Line Blockage Between Ipswich and Stowmarket. Figure \ref{Fig: Phi-3-mini contingency} shows the results which appears correlated to the response from Bing Co-Pilot. As the response is not detailed a conclusion that is was also insufficient was drawn, yielding our chatbot to be superior. 


\subsection{Evaluation and Comparison}
The reviewed chatbots appear to be subprior with general dialogue, specifically conversational responses. However, both models fall short of the tasks 2-5 outlined in \ref{Sec: Aim and Objs}. Solely based on these tasks, the aforementioned bots are not sufficient leaving our chatbot most acceptable.