{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating A Regression Model To Predict Train Delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/bgf_wq4d7pxdmbbq4nl3gqg00000gn/T/ipykernel_3284/3543399490.py:23: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir, file))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd, numpy as np, copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "# Set the option to display all columns, without the \"...\" in the middle\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Directory where the csv data is stored\n",
    "train_data_dir = 'data/delay data'\n",
    "\n",
    "def find_csv_filenames(path_to_dir, suffix=\".csv\"):\n",
    "    filenames = os.listdir(path_to_dir)\n",
    "    return [filename for filename in filenames if filename.endswith(suffix)]\n",
    "\n",
    "def concatenate_csv_files(directory):\n",
    "    frames = []\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                df = pd.read_csv(os.path.join(subdir, file))\n",
    "                frames.append(df)\n",
    "    return pd.concat(frames)\n",
    "\n",
    "\n",
    "train_dataset = concatenate_csv_files(train_data_dir)\n",
    "\n",
    "# train_dataset.to_csv('./delay_concatenate_train_dataset.csv')\n",
    "\n",
    "train_dataset_copy = train_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns for Binary Encoding: ['arr_atRemoved', 'pass_atRemoved', 'dep_atRemoved']\n",
      "Columns for One Hot Encoding: ['dep_wet']\n",
      "Columns for Label Encoding: ['tpl']\n",
      "Columns for Target Encoding: ['pta', 'ptd', 'wta', 'wtp', 'wtd', 'arr_et', 'arr_wet', 'pass_et', 'dep_et', 'arr_at', 'pass_at', 'dep_at']\n",
      "\n",
      "____________________\n",
      "\n",
      "Index(['rid', 'tpl', 'pta', 'ptd', 'wtp', 'arr_et', 'arr_wet', 'pass_et',\n",
      "       'dep_et', 'dep_wet', 'arr_at', 'pass_at', 'dep_at', 'cr_code',\n",
      "       'lr_code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# List to store column names for different encoding types\n",
    "columns_for_binary_encoding = []\n",
    "columns_for_one_hot_encoding = []\n",
    "columns_for_label_encoding = []\n",
    "columns_for_target_encoding = []\n",
    "\n",
    "# Dictionary to store encoding type for each column\n",
    "encoding_dict = {}\n",
    "\n",
    "# Iterate over columns in the train_dataset dataframe\n",
    "for column in train_dataset.columns:\n",
    "    # Check if the column is of object type\n",
    "    if train_dataset[column].dtype == 'object':\n",
    "        # Check the number of unique values in the column\n",
    "        if len(train_dataset[column].unique()) == 2:\n",
    "            columns_for_binary_encoding.append(column)\n",
    "            encoding_dict[column] = 'Binary Encoding'\n",
    "        elif len(train_dataset[column].unique()) > 2 and len(train_dataset[column].unique()) < 10:\n",
    "            columns_for_one_hot_encoding.append(column)\n",
    "            encoding_dict[column] = 'One Hot Encoding'\n",
    "        elif len(train_dataset[column].unique()) > 11 and len(train_dataset[column].unique()) < 50:\n",
    "            columns_for_label_encoding.append(column)\n",
    "            encoding_dict[column] = 'Label Encoding'\n",
    "        elif len(train_dataset[column].unique()) > 50:\n",
    "            columns_for_target_encoding.append(column)\n",
    "            encoding_dict[column] = 'Target Encoding'\n",
    "\n",
    "# Print the columns for different encoding types\n",
    "print('Columns for Binary Encoding:', columns_for_binary_encoding)\n",
    "print('Columns for One Hot Encoding:', columns_for_one_hot_encoding)\n",
    "print('Columns for Label Encoding:', columns_for_label_encoding)\n",
    "print('Columns for Target Encoding:', columns_for_target_encoding)\n",
    "print('\\n' + '_' * 20 + '\\n')\n",
    "\n",
    "# Create a DataFrame to display the unique counts and encoding types for each column\n",
    "unique_counts = pd.DataFrame.from_records(\n",
    "    [(col, train_dataset[col].dtype, len(train_dataset[col].unique()), encoding_dict.get(col, 'No Encoding')) for col in train_dataset.columns],\n",
    "    columns=['Column_Name', 'Data_Type', 'Num_Unique_Values', 'Encoding']\n",
    ")\n",
    "\n",
    "# Drop columns for binary encoding and unnecessary columns from the train_dataset dataframe\n",
    "train_dataset.drop(columns=columns_for_binary_encoding, inplace=True)\n",
    "train_dataset.drop(columns=['pass_wet', 'wta', 'wtd'], inplace=True)\n",
    "\n",
    "# Print the remaining columns in the train_dataset dataframe\n",
    "print(train_dataset.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a departed from LDN column\n",
    "\n",
    "This code will extract the departing time from london. If no ground truth departing time was recorded, the predicted, planned and estimated times are used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>tpl</th>\n",
       "      <th>pta</th>\n",
       "      <th>ptd</th>\n",
       "      <th>wtp</th>\n",
       "      <th>arr_et</th>\n",
       "      <th>arr_wet</th>\n",
       "      <th>pass_et</th>\n",
       "      <th>dep_et</th>\n",
       "      <th>dep_wet</th>\n",
       "      <th>arr_at</th>\n",
       "      <th>pass_at</th>\n",
       "      <th>dep_at_x</th>\n",
       "      <th>cr_code</th>\n",
       "      <th>lr_code</th>\n",
       "      <th>depart_from_LDN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>LIVST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BTHNLGR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BOWJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>MRYLAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:06:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>STFD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713985</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>DISS</td>\n",
       "      <td>01:03</td>\n",
       "      <td>01:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713986</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>TROWSEJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:19:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713987</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>TRWSSBJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713988</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>NRCHTPJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:20:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713989</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>NRCH</td>\n",
       "      <td>01:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1713990 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rid      tpl    pta    ptd       wtp arr_et arr_wet  \\\n",
       "0        202009016712165    LIVST    NaN  07:00       NaN    NaN     NaN   \n",
       "1        202009016712165  BTHNLGR    NaN    NaN     07:03    NaN     NaN   \n",
       "2        202009016712165     BOWJ    NaN    NaN     07:05    NaN     NaN   \n",
       "3        202009016712165  MRYLAND    NaN    NaN  07:06:30    NaN     NaN   \n",
       "4        202009016712165     STFD    NaN    NaN     07:06    NaN     NaN   \n",
       "...                  ...      ...    ...    ...       ...    ...     ...   \n",
       "1713985  202204308009724     DISS  01:03  01:05       NaN    NaN     NaN   \n",
       "1713986  202204308009724  TROWSEJ    NaN    NaN  01:19:30    NaN     NaN   \n",
       "1713987  202204308009724  TRWSSBJ    NaN    NaN     01:20    NaN     NaN   \n",
       "1713988  202204308009724  NRCHTPJ    NaN    NaN  01:20:30    NaN     NaN   \n",
       "1713989  202204308009724     NRCH  01:22    NaN       NaN    NaN     NaN   \n",
       "\n",
       "        pass_et dep_et dep_wet arr_at pass_at dep_at_x  cr_code  lr_code  \\\n",
       "0           NaN    NaN     NaN    NaN     NaN    06:59      NaN      NaN   \n",
       "1           NaN    NaN     NaN    NaN   07:03      NaN      NaN      NaN   \n",
       "2           NaN    NaN     NaN    NaN   07:04      NaN      NaN      NaN   \n",
       "3           NaN    NaN     NaN    NaN   07:06      NaN      NaN      NaN   \n",
       "4         07:07    NaN     NaN    NaN     NaN      NaN      NaN      NaN   \n",
       "...         ...    ...     ...    ...     ...      ...      ...      ...   \n",
       "1713985     NaN    NaN     NaN  01:02     NaN    01:04      NaN      NaN   \n",
       "1713986     NaN    NaN     NaN    NaN   01:18      NaN      NaN      NaN   \n",
       "1713987   01:18    NaN     NaN    NaN     NaN      NaN      NaN      NaN   \n",
       "1713988     NaN    NaN     NaN    NaN   01:19      NaN      NaN      NaN   \n",
       "1713989     NaN    NaN     NaN  01:21     NaN      NaN      NaN      NaN   \n",
       "\n",
       "        depart_from_LDN  \n",
       "0                 06:59  \n",
       "1                 06:59  \n",
       "2                 06:59  \n",
       "3                 06:59  \n",
       "4                 06:59  \n",
       "...                 ...  \n",
       "1713985           23:29  \n",
       "1713986           23:29  \n",
       "1713987           23:29  \n",
       "1713988           23:29  \n",
       "1713989           23:29  \n",
       "\n",
       "[1713990 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (train_dataset['tpl'] == 'LIVST') & train_dataset['dep_at'].isna()\n",
    "train_dataset.loc[mask, 'dep_at'] = train_dataset.loc[mask, 'dep_et']\n",
    "\n",
    "mask = (train_dataset['tpl'] == 'LIVST') & (train_dataset['dep_at'].isna())\n",
    "train_dataset.loc[mask, 'dep_at'] = train_dataset.loc[mask, 'ptd']\n",
    "\n",
    "mask = (train_dataset['tpl'] == 'NRCH') & (train_dataset['dep_at'].isna())\n",
    "train_dataset.loc[mask, 'dep_at'] = train_dataset.loc[mask, 'arr_et']\n",
    "\n",
    "LDN_departure_times = train_dataset[train_dataset['tpl'] == 'LIVST'][['rid', 'dep_at']].rename(columns={'ptd': 'departure_time'})\n",
    "NRW_arrival_times = train_dataset[train_dataset['tpl'] == 'NRCH'][['rid', 'arr_at']]\n",
    "\n",
    "train_dataset = pd.merge(train_dataset, LDN_departure_times, on='rid', how='left')\n",
    "train_dataset.rename(columns={'dep_at_y' : 'depart_from_LDN'}, inplace=True)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the arrival at Norwich station\n",
    "\n",
    "The time of arrival at Norwich is added to a column to each group of journeys (rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>tpl</th>\n",
       "      <th>pta</th>\n",
       "      <th>ptd</th>\n",
       "      <th>wtp</th>\n",
       "      <th>arr_et</th>\n",
       "      <th>arr_wet</th>\n",
       "      <th>pass_et</th>\n",
       "      <th>dep_et</th>\n",
       "      <th>dep_wet</th>\n",
       "      <th>arr_at</th>\n",
       "      <th>pass_at</th>\n",
       "      <th>dep_at_x</th>\n",
       "      <th>cr_code</th>\n",
       "      <th>lr_code</th>\n",
       "      <th>depart_from_LDN</th>\n",
       "      <th>arrival_at_norwich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>LIVST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BTHNLGR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BOWJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>MRYLAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:06:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>STFD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:59</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713985</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>DISS</td>\n",
       "      <td>01:03</td>\n",
       "      <td>01:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:29</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713986</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>TROWSEJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:19:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:29</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713987</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>TRWSSBJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:29</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713988</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>NRCHTPJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:20:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:29</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713989</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>NRCH</td>\n",
       "      <td>01:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:29</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1713990 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rid      tpl    pta    ptd       wtp arr_et arr_wet  \\\n",
       "0        202009016712165    LIVST    NaN  07:00       NaN    NaN     NaN   \n",
       "1        202009016712165  BTHNLGR    NaN    NaN     07:03    NaN     NaN   \n",
       "2        202009016712165     BOWJ    NaN    NaN     07:05    NaN     NaN   \n",
       "3        202009016712165  MRYLAND    NaN    NaN  07:06:30    NaN     NaN   \n",
       "4        202009016712165     STFD    NaN    NaN     07:06    NaN     NaN   \n",
       "...                  ...      ...    ...    ...       ...    ...     ...   \n",
       "1713985  202204308009724     DISS  01:03  01:05       NaN    NaN     NaN   \n",
       "1713986  202204308009724  TROWSEJ    NaN    NaN  01:19:30    NaN     NaN   \n",
       "1713987  202204308009724  TRWSSBJ    NaN    NaN     01:20    NaN     NaN   \n",
       "1713988  202204308009724  NRCHTPJ    NaN    NaN  01:20:30    NaN     NaN   \n",
       "1713989  202204308009724     NRCH  01:22    NaN       NaN    NaN     NaN   \n",
       "\n",
       "        pass_et dep_et dep_wet arr_at pass_at dep_at_x  cr_code  lr_code  \\\n",
       "0           NaN    NaN     NaN    NaN     NaN    06:59      NaN      NaN   \n",
       "1           NaN    NaN     NaN    NaN   07:03      NaN      NaN      NaN   \n",
       "2           NaN    NaN     NaN    NaN   07:04      NaN      NaN      NaN   \n",
       "3           NaN    NaN     NaN    NaN   07:06      NaN      NaN      NaN   \n",
       "4         07:07    NaN     NaN    NaN     NaN      NaN      NaN      NaN   \n",
       "...         ...    ...     ...    ...     ...      ...      ...      ...   \n",
       "1713985     NaN    NaN     NaN  01:02     NaN    01:04      NaN      NaN   \n",
       "1713986     NaN    NaN     NaN    NaN   01:18      NaN      NaN      NaN   \n",
       "1713987   01:18    NaN     NaN    NaN     NaN      NaN      NaN      NaN   \n",
       "1713988     NaN    NaN     NaN    NaN   01:19      NaN      NaN      NaN   \n",
       "1713989     NaN    NaN     NaN  01:21     NaN      NaN      NaN      NaN   \n",
       "\n",
       "        depart_from_LDN arrival_at_norwich  \n",
       "0                 06:59              08:52  \n",
       "1                 06:59              08:52  \n",
       "2                 06:59              08:52  \n",
       "3                 06:59              08:52  \n",
       "4                 06:59              08:52  \n",
       "...                 ...                ...  \n",
       "1713985           23:29              01:21  \n",
       "1713986           23:29              01:21  \n",
       "1713987           23:29              01:21  \n",
       "1713988           23:29              01:21  \n",
       "1713989           23:29              01:21  \n",
       "\n",
       "[1713990 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the 'arr_at' column in NRW_arrival_times dataframe to 'arrival_at_norwich'\n",
    "NRW_arrival_times.rename(columns={'arr_at' : 'arrival_at_norwich'}, inplace=True)\n",
    "\n",
    "# Merge the train_dataset dataframe with NRW_arrival_times dataframe on the 'rid' column\n",
    "train_dataset = pd.merge(train_dataset, NRW_arrival_times, on='rid', how='left')\n",
    "\n",
    "# Display the updated train_dataset dataframe\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>tpl</th>\n",
       "      <th>depart_from_LDN</th>\n",
       "      <th>arrival_at_norwich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>LIVST</td>\n",
       "      <td>06:59</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BTHNLGR</td>\n",
       "      <td>06:59</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BOWJ</td>\n",
       "      <td>06:59</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>MRYLAND</td>\n",
       "      <td>06:59</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>STFD</td>\n",
       "      <td>06:59</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713985</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>DISS</td>\n",
       "      <td>23:29</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713986</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>TROWSEJ</td>\n",
       "      <td>23:29</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713987</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>TRWSSBJ</td>\n",
       "      <td>23:29</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713988</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>NRCHTPJ</td>\n",
       "      <td>23:29</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713989</th>\n",
       "      <td>202204308009724</td>\n",
       "      <td>NRCH</td>\n",
       "      <td>23:29</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1713990 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rid      tpl depart_from_LDN arrival_at_norwich\n",
       "0        202009016712165    LIVST           06:59              08:52\n",
       "1        202009016712165  BTHNLGR           06:59              08:52\n",
       "2        202009016712165     BOWJ           06:59              08:52\n",
       "3        202009016712165  MRYLAND           06:59              08:52\n",
       "4        202009016712165     STFD           06:59              08:52\n",
       "...                  ...      ...             ...                ...\n",
       "1713985  202204308009724     DISS           23:29              01:21\n",
       "1713986  202204308009724  TROWSEJ           23:29              01:21\n",
       "1713987  202204308009724  TRWSSBJ           23:29              01:21\n",
       "1713988  202204308009724  NRCHTPJ           23:29              01:21\n",
       "1713989  202204308009724     NRCH           23:29              01:21\n",
       "\n",
       "[1713990 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[['rid','tpl','depart_from_LDN', 'arrival_at_norwich']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the string values into date values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time strings to datetime objects for calculation\n",
    "train_dataset['depart_from_LDN'] = pd.to_datetime(train_dataset['depart_from_LDN'], format='%H:%M')  # Convert depart_from_LDN column to datetime\n",
    "train_dataset['dep_at_x'] = pd.to_datetime(train_dataset['dep_at_x'], format='%H:%M')  # Convert dep_at_x column to datetime\n",
    "\n",
    "train_dataset['pass_at'] = pd.to_datetime(train_dataset['pass_at'], format='%H:%M')  # Convert pass_at column to datetime\n",
    "train_dataset['pass_et'] = pd.to_datetime(train_dataset['pass_et'], format='%H:%M')  # Convert pass_et column to datetime\n",
    "train_dataset['arr_at'] = pd.to_datetime(train_dataset['arr_at'], format='%H:%M')  # Convert arr_at column to datetime\n",
    "train_dataset['dep_et'] = pd.to_datetime(train_dataset['dep_et'], format='%H:%M')  # Convert dep_et column to datetime\n",
    "train_dataset['arr_wet'] = pd.to_datetime(train_dataset['arr_wet'], format='%H:%M')  # Convert arr_wet column to datetime\n",
    "train_dataset['ptd'] = pd.to_datetime(train_dataset['ptd'], format='%H:%M')  # Convert ptd column to datetime\n",
    "train_dataset['pta'] = pd.to_datetime(train_dataset['pta'], format='%H:%M')  # Convert pta column to datetime\n",
    "\n",
    "# mask = (train_dataset['tpl'] == 'LIVST') & (train_dataset['dep_at_y'].isna())\n",
    "# train_dataset.loc[mask, 'dep_at_y'] = train_dataset.loc[mask, 'dep_et']\n",
    "# train_dataset.loc[mask, 'dep_at_x'] = train_dataset.loc[mask, 'dep_et']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>tpl</th>\n",
       "      <th>pta</th>\n",
       "      <th>ptd</th>\n",
       "      <th>wtp</th>\n",
       "      <th>arr_et</th>\n",
       "      <th>arr_wet</th>\n",
       "      <th>pass_et</th>\n",
       "      <th>dep_et</th>\n",
       "      <th>dep_wet</th>\n",
       "      <th>arr_at</th>\n",
       "      <th>pass_at</th>\n",
       "      <th>dep_at_x</th>\n",
       "      <th>cr_code</th>\n",
       "      <th>lr_code</th>\n",
       "      <th>depart_from_LDN</th>\n",
       "      <th>arrival_at_norwich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>LIVST</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BTHNLGR</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>07:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 07:03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BOWJ</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>07:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 07:04:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>MRYLAND</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>07:06:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 07:06:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>STFD</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>07:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 07:07:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rid      tpl pta                 ptd       wtp arr_et arr_wet  \\\n",
       "0  202009016712165    LIVST NaT 1900-01-01 07:00:00       NaN    NaN     NaT   \n",
       "1  202009016712165  BTHNLGR NaT                 NaT     07:03    NaN     NaT   \n",
       "2  202009016712165     BOWJ NaT                 NaT     07:05    NaN     NaT   \n",
       "3  202009016712165  MRYLAND NaT                 NaT  07:06:30    NaN     NaT   \n",
       "4  202009016712165     STFD NaT                 NaT     07:06    NaN     NaT   \n",
       "\n",
       "              pass_et dep_et dep_wet arr_at             pass_at  \\\n",
       "0                 NaT    NaT     NaN    NaT                 NaT   \n",
       "1                 NaT    NaT     NaN    NaT 1900-01-01 07:03:00   \n",
       "2                 NaT    NaT     NaN    NaT 1900-01-01 07:04:00   \n",
       "3                 NaT    NaT     NaN    NaT 1900-01-01 07:06:00   \n",
       "4 1900-01-01 07:07:00    NaT     NaN    NaT                 NaT   \n",
       "\n",
       "             dep_at_x  cr_code  lr_code     depart_from_LDN arrival_at_norwich  \n",
       "0 1900-01-01 06:59:00      NaN      NaN 1900-01-01 06:59:00              08:52  \n",
       "1                 NaT      NaN      NaN 1900-01-01 06:59:00              08:52  \n",
       "2                 NaT      NaN      NaN 1900-01-01 06:59:00              08:52  \n",
       "3                 NaT      NaN      NaN 1900-01-01 06:59:00              08:52  \n",
       "4                 NaT      NaN      NaN 1900-01-01 06:59:00              08:52  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['temp_dep_at'] = train_dataset['dep_at_x']\n",
    "train_dataset.loc[train_dataset['temp_dep_at'].isna(),'temp_dep_at'] = train_dataset['pass_at']\n",
    "train_dataset.loc[train_dataset['temp_dep_at'].isna(),'temp_dep_at'] = train_dataset['wtp']\n",
    "\n",
    "\n",
    "train_dataset['temp_arr_at'] = train_dataset['arr_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pta</th>\n",
       "      <th>arr_at</th>\n",
       "      <th>ptd</th>\n",
       "      <th>dep_at_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 07:00:00</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713985</th>\n",
       "      <td>1900-01-01 01:03:00</td>\n",
       "      <td>1900-01-01 01:02:00</td>\n",
       "      <td>1900-01-01 01:05:00</td>\n",
       "      <td>1900-01-01 01:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713986</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713987</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713988</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713989</th>\n",
       "      <td>1900-01-01 01:22:00</td>\n",
       "      <td>1900-01-01 01:21:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1713990 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pta              arr_at                 ptd  \\\n",
       "0                       NaT                 NaT 1900-01-01 07:00:00   \n",
       "1                       NaT                 NaT                 NaT   \n",
       "2                       NaT                 NaT                 NaT   \n",
       "3                       NaT                 NaT                 NaT   \n",
       "4                       NaT                 NaT                 NaT   \n",
       "...                     ...                 ...                 ...   \n",
       "1713985 1900-01-01 01:03:00 1900-01-01 01:02:00 1900-01-01 01:05:00   \n",
       "1713986                 NaT                 NaT                 NaT   \n",
       "1713987                 NaT                 NaT                 NaT   \n",
       "1713988                 NaT                 NaT                 NaT   \n",
       "1713989 1900-01-01 01:22:00 1900-01-01 01:21:00                 NaT   \n",
       "\n",
       "                   dep_at_x  \n",
       "0       1900-01-01 06:59:00  \n",
       "1                       NaT  \n",
       "2                       NaT  \n",
       "3                       NaT  \n",
       "4                       NaT  \n",
       "...                     ...  \n",
       "1713985 1900-01-01 01:04:00  \n",
       "1713986                 NaT  \n",
       "1713987                 NaT  \n",
       "1713988                 NaT  \n",
       "1713989                 NaT  \n",
       "\n",
       "[1713990 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[['pta','arr_at', 'ptd','dep_at_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19        0 days 00:02:00\n",
       "20        0 days 00:02:00\n",
       "22        0 days 00:03:00\n",
       "25        0 days 00:02:00\n",
       "27        0 days 00:02:00\n",
       "                ...      \n",
       "1713978   0 days 00:01:00\n",
       "1713980   0 days 00:02:00\n",
       "1713983   0 days 00:01:00\n",
       "1713985   0 days 00:01:00\n",
       "1713989   0 days 00:01:00\n",
       "Length: 328416, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_dataset['pta'] - train_dataset['arr_at']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0 days 00:01:00\n",
       "15        0 days 00:01:00\n",
       "19        0 days 00:01:00\n",
       "20        0 days 00:00:00\n",
       "22        0 days 00:01:00\n",
       "                ...      \n",
       "1713977   0 days 00:01:00\n",
       "1713978   0 days 00:00:00\n",
       "1713980   0 days 00:01:00\n",
       "1713983   0 days 00:01:00\n",
       "1713985   0 days 00:01:00\n",
       "Length: 354894, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_dataset['ptd'] - train_dataset['dep_at_x']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rid                            int64\n",
       "tpl                           object\n",
       "pta                   datetime64[ns]\n",
       "ptd                   datetime64[ns]\n",
       "wtp                           object\n",
       "arr_et                        object\n",
       "arr_wet               datetime64[ns]\n",
       "pass_et               datetime64[ns]\n",
       "dep_et                datetime64[ns]\n",
       "dep_wet                       object\n",
       "arr_at                datetime64[ns]\n",
       "pass_at               datetime64[ns]\n",
       "dep_at_x              datetime64[ns]\n",
       "cr_code                      float64\n",
       "lr_code                      float64\n",
       "depart_from_LDN       datetime64[ns]\n",
       "arrival_at_norwich            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the departing time from each individual station\n",
    "\n",
    "Similar to extracting the a the departing time for London. A sequential extraction of each stations departing time is made, if no ground truth values were recorded, the predicted, estiamted and planned values are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['depart_from_current_station'] = train_dataset['dep_at_x']\n",
    "train_dataset['depart_from_current_station'] = train_dataset['depart_from_current_station'].fillna(train_dataset['dep_et'])\n",
    "train_dataset['depart_from_current_station'] = train_dataset['depart_from_current_station'].fillna(train_dataset['ptd'])\n",
    "train_dataset['depart_from_current_station'] = train_dataset['depart_from_current_station'].fillna(train_dataset['wtp'])\n",
    "train_dataset['depart_from_current_station'] = train_dataset['depart_from_current_station'].fillna(train_dataset['pass_at'])\n",
    "train_dataset['depart_from_current_station'] = train_dataset['depart_from_current_station'].fillna(train_dataset['dep_et'])\n",
    "train_dataset['depart_from_current_station'] = train_dataset['depart_from_current_station'].fillna(train_dataset['pta'])\n",
    "train_dataset['depart_from_current_station'] = train_dataset['depart_from_current_station'].fillna(train_dataset['arr_wet'])\n",
    "train_dataset['depart_from_current_station'] = train_dataset['depart_from_current_station'].fillna(train_dataset['arr_at'])\n",
    "\n",
    "\n",
    "# train_dataset['arrive_at_NRW'] = train_dataset.loc[train_dataset['rid']]\n",
    "\n",
    "# train_dataset['time_passed'] = train_dataset['time_passed'].fillna(train_dataset.loc[train_dataset['tpl']== 'NRCH', 'arr_at'] - train_dataset['dep_at_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>tpl</th>\n",
       "      <th>pta</th>\n",
       "      <th>ptd</th>\n",
       "      <th>wtp</th>\n",
       "      <th>arr_et</th>\n",
       "      <th>arr_wet</th>\n",
       "      <th>pass_et</th>\n",
       "      <th>dep_et</th>\n",
       "      <th>dep_wet</th>\n",
       "      <th>arr_at</th>\n",
       "      <th>pass_at</th>\n",
       "      <th>dep_at_x</th>\n",
       "      <th>cr_code</th>\n",
       "      <th>lr_code</th>\n",
       "      <th>depart_from_LDN</th>\n",
       "      <th>arrival_at_norwich</th>\n",
       "      <th>depart_from_current_station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>LIVST</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>08:52</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BTHNLGR</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>07:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 07:03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>08:52</td>\n",
       "      <td>2024-05-13 07:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BOWJ</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>07:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 07:04:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>08:52</td>\n",
       "      <td>2024-05-13 07:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>MRYLAND</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>07:06:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 07:06:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>08:52</td>\n",
       "      <td>2024-05-13 07:06:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>STFD</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>07:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1900-01-01 07:07:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>08:52</td>\n",
       "      <td>2024-05-13 07:06:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rid      tpl pta                 ptd       wtp arr_et arr_wet  \\\n",
       "0  202009016712165    LIVST NaT 1900-01-01 07:00:00       NaN    NaN     NaT   \n",
       "1  202009016712165  BTHNLGR NaT                 NaT     07:03    NaN     NaT   \n",
       "2  202009016712165     BOWJ NaT                 NaT     07:05    NaN     NaT   \n",
       "3  202009016712165  MRYLAND NaT                 NaT  07:06:30    NaN     NaT   \n",
       "4  202009016712165     STFD NaT                 NaT     07:06    NaN     NaT   \n",
       "\n",
       "              pass_et dep_et dep_wet arr_at             pass_at  \\\n",
       "0                 NaT    NaT     NaN    NaT                 NaT   \n",
       "1                 NaT    NaT     NaN    NaT 1900-01-01 07:03:00   \n",
       "2                 NaT    NaT     NaN    NaT 1900-01-01 07:04:00   \n",
       "3                 NaT    NaT     NaN    NaT 1900-01-01 07:06:00   \n",
       "4 1900-01-01 07:07:00    NaT     NaN    NaT                 NaT   \n",
       "\n",
       "             dep_at_x  cr_code  lr_code     depart_from_LDN  \\\n",
       "0 1900-01-01 06:59:00      NaN      NaN 1900-01-01 06:59:00   \n",
       "1                 NaT      NaN      NaN 1900-01-01 06:59:00   \n",
       "2                 NaT      NaN      NaN 1900-01-01 06:59:00   \n",
       "3                 NaT      NaN      NaN 1900-01-01 06:59:00   \n",
       "4                 NaT      NaN      NaN 1900-01-01 06:59:00   \n",
       "\n",
       "  arrival_at_norwich depart_from_current_station  \n",
       "0              08:52         1900-01-01 06:59:00  \n",
       "1              08:52         2024-05-13 07:03:00  \n",
       "2              08:52         2024-05-13 07:05:00  \n",
       "3              08:52         2024-05-13 07:06:30  \n",
       "4              08:52         2024-05-13 07:06:00  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating functions to convert the time value to numeric value and reverse the numeric value back to time value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a time string to seconds\n",
    "def convert_string_to_seconds(time_str):\n",
    "    \"\"\"\n",
    "    Converts a time string to the total number of seconds.\n",
    "    \n",
    "    Parameters:\n",
    "    time_str (str): The time string to be converted. It should be in the format 'HH:MM:SS' or 'HH:MM'.\n",
    "    \n",
    "    Returns:\n",
    "    int: The total number of seconds represented by the time string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to convert the time string to datetime format with seconds\n",
    "        date_time_value = pd.to_datetime(time_str, format='%H:%M:%S')\n",
    "        total_seconds = date_time_value.hour * 3600 + date_time_value.minute * 60 + date_time_value.second\n",
    "    \n",
    "    except:\n",
    "        # If the conversion fails, try to convert the time string to datetime format without seconds\n",
    "        date_time_value = pd.to_datetime(time_str, format='%H:%M')\n",
    "        total_seconds = date_time_value.hour * 3600 + date_time_value.minute * 60 + date_time_value.second\n",
    "        \n",
    "    return total_seconds\n",
    "\n",
    "# Function to convert seconds to a time string\n",
    "def convert_seconds_to_string(seconds):\n",
    "    \"\"\"\n",
    "    Converts the given number of seconds into a string representation of time in the format HH:MM:SS.\n",
    "\n",
    "    Parameters:\n",
    "    seconds (int): The number of seconds to convert.\n",
    "\n",
    "    Returns:\n",
    "    str: The string representation of time in the format HH:MM:SS.\n",
    "    \"\"\"\n",
    "    hours = seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    seconds = seconds % 60\n",
    "    return \"{:02d}:{:02d}:{:02d}\".format(int(hours), int(minutes), int(seconds))\n",
    "\n",
    "def convert_string_to_seconds_vectorized(time_series):\n",
    "    \"\"\"\n",
    "    Converts a time series represented as strings in the format 'HH:MM:SS' or 'HH:MM' to a vector of total seconds.\n",
    "\n",
    "    Parameters:\n",
    "    time_series (pandas.Series): A pandas Series containing time series data in string format.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: A pandas Series containing the total seconds for each time value in the input time series.\n",
    "\n",
    "    Example:\n",
    "    >>> time_series = pd.Series(['12:34:56', '01:23:45', '10:00'])\n",
    "    >>> convert_string_to_seconds_vectorized(time_series)\n",
    "    0    45296\n",
    "    1     5025\n",
    "    2    36000\n",
    "    dtype: int64\n",
    "    \"\"\"\n",
    "    \n",
    "    time_series_dt = pd.to_datetime(time_series, format='%H:%M:%S', errors='coerce')\n",
    "    time_series_dt[time_series_dt.isna()] = pd.to_datetime(time_series[time_series_dt.isna()], format='%H:%M')\n",
    "    total_seconds = time_series_dt.dt.hour * 3600 + time_series_dt.dt.minute * 60 + time_series_dt.dt.second\n",
    "    return total_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the features that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['rid','tpl','depart_from_LDN', 'depart_from_current_station', 'arrival_at_norwich']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>tpl</th>\n",
       "      <th>depart_from_LDN</th>\n",
       "      <th>depart_from_current_station</th>\n",
       "      <th>arrival_at_norwich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>LIVST</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BTHNLGR</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>2024-05-13 07:03:00</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BOWJ</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>2024-05-13 07:05:00</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>MRYLAND</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>2024-05-13 07:06:30</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>STFD</td>\n",
       "      <td>1900-01-01 06:59:00</td>\n",
       "      <td>2024-05-13 07:06:00</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rid      tpl     depart_from_LDN depart_from_current_station  \\\n",
       "0  202009016712165    LIVST 1900-01-01 06:59:00         1900-01-01 06:59:00   \n",
       "1  202009016712165  BTHNLGR 1900-01-01 06:59:00         2024-05-13 07:03:00   \n",
       "2  202009016712165     BOWJ 1900-01-01 06:59:00         2024-05-13 07:05:00   \n",
       "3  202009016712165  MRYLAND 1900-01-01 06:59:00         2024-05-13 07:06:30   \n",
       "4  202009016712165     STFD 1900-01-01 06:59:00         2024-05-13 07:06:00   \n",
       "\n",
       "  arrival_at_norwich  \n",
       "0              08:52  \n",
       "1              08:52  \n",
       "2              08:52  \n",
       "3              08:52  \n",
       "4              08:52  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[features].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the feature column vales to numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each feature in the 'features' list starting from the third feature\n",
    "for feature in features[2:]:\n",
    "    pass\n",
    "    # Convert the string values in the specified feature column to seconds using the 'convert_string_to_seconds_vectorized' function\n",
    "    train_dataset[feature] = convert_string_to_seconds_vectorized(train_dataset[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>tpl</th>\n",
       "      <th>depart_from_LDN</th>\n",
       "      <th>depart_from_current_station</th>\n",
       "      <th>arrival_at_norwich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>LIVST</td>\n",
       "      <td>25140.0</td>\n",
       "      <td>25140</td>\n",
       "      <td>31920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BTHNLGR</td>\n",
       "      <td>25140.0</td>\n",
       "      <td>25380</td>\n",
       "      <td>31920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>BOWJ</td>\n",
       "      <td>25140.0</td>\n",
       "      <td>25500</td>\n",
       "      <td>31920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>MRYLAND</td>\n",
       "      <td>25140.0</td>\n",
       "      <td>25590</td>\n",
       "      <td>31920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202009016712165</td>\n",
       "      <td>STFD</td>\n",
       "      <td>25140.0</td>\n",
       "      <td>25560</td>\n",
       "      <td>31920.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rid      tpl  depart_from_LDN  depart_from_current_station  \\\n",
       "0  202009016712165    LIVST          25140.0                        25140   \n",
       "1  202009016712165  BTHNLGR          25140.0                        25380   \n",
       "2  202009016712165     BOWJ          25140.0                        25500   \n",
       "3  202009016712165  MRYLAND          25140.0                        25590   \n",
       "4  202009016712165     STFD          25140.0                        25560   \n",
       "\n",
       "   arrival_at_norwich  \n",
       "0             31920.0  \n",
       "1             31920.0  \n",
       "2             31920.0  \n",
       "3             31920.0  \n",
       "4             31920.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[features].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the train station code using Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Original Value  Encoded Value\n",
      "0            BOWJ              0\n",
      "1         BROXBRN              1\n",
      "2         BRTWOOD              2\n",
      "3         BTHNLGR              3\n",
      "4         CHDWLHT              4\n",
      "5         CHESHNT              5\n",
      "6         CHLMSFD              6\n",
      "7         CLCHSTR              7\n",
      "8            DISS              8\n",
      "9          FRSTGT              9\n",
      "10        FRSTGTJ             10\n",
      "11        GIDEAPK             11\n",
      "12        GIDEPKJ             12\n",
      "13        GODMAYS             13\n",
      "14        HAGHLYJ             14\n",
      "15        HAKNYNM             15\n",
      "16        HFLPEVL             16\n",
      "17        HRLDWOD             17\n",
      "18        ILFELEJ             18\n",
      "19         ILFORD             19\n",
      "20        INGTSTL             20\n",
      "21        INGTSTN             21\n",
      "22        IPSWEPJ             22\n",
      "23        IPSWESJ             23\n",
      "24        IPSWHJN             24\n",
      "25        IPSWICH             25\n",
      "26        KELVEDN             26\n",
      "27          LIVST             27\n",
      "28        MANNGTR             28\n",
      "29         MANRPK             29\n",
      "30        MRKSTEY             30\n",
      "31        MRYLAND             31\n",
      "32        NEEDHAM             32\n",
      "33           NRCH             33\n",
      "34        NRCHTPJ             34\n",
      "35        ROMFORD             35\n",
      "36        SEVNSIS             36\n",
      "37        SHENFLD             37\n",
      "38           STFD             38\n",
      "39        STWMDGL             39\n",
      "40        STWMRKT             40\n",
      "41        SVNKNGS             41\n",
      "42        TROWFLR             42\n",
      "43        TROWSEJ             43\n",
      "44        TRWSSBJ             44\n",
      "45           WARE             45\n",
      "46        WITHAME             46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# create the LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit the encoder\n",
    "le.fit(train_dataset['tpl'])\n",
    "\n",
    "joblib.dump(le, 'train_station_encoder_model.sav', compress=3)\n",
    "\n",
    "# to de-code values use decoded_values = loaded_model.inverse_transform(encoded_values)\n",
    "\n",
    "\n",
    "# create a DataFrame with the original and encoded values\n",
    "encoding_table = pd.DataFrame({\n",
    "    'Original Value': le.classes_,\n",
    "    'Encoded Value': range(len(le.classes_))\n",
    "})\n",
    "\n",
    "print(encoding_table)\n",
    "\n",
    "train_dataset['tpl'] = le.fit_transform(train_dataset['tpl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/bgf_wq4d7pxdmbbq4nl3gqg00000gn/T/ipykernel_7374/3156949966.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  shape_counts = df.groupby('rid').apply(lambda x: x.shape).value_counts()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shape</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 18)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2, 18)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(3, 18)</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(4, 18)</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(5, 18)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(6, 18)</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(7, 18)</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(8, 18)</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(9, 18)</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(10, 18)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(11, 18)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(12, 18)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(13, 18)</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(14, 18)</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(15, 18)</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(16, 18)</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(17, 18)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(18, 18)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(19, 18)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(20, 18)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(21, 18)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(22, 18)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(23, 18)</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(24, 18)</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(25, 18)</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(26, 18)</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(27, 18)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(28, 18)</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(29, 18)</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(30, 18)</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(31, 18)</td>\n",
       "      <td>9576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(32, 18)</td>\n",
       "      <td>42459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(33, 18)</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(34, 18)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(35, 18)</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Shape  Count\n",
       "0    (1, 18)      1\n",
       "1    (2, 18)     20\n",
       "2    (3, 18)     61\n",
       "3    (4, 18)     36\n",
       "4    (5, 18)     10\n",
       "5    (6, 18)    504\n",
       "6    (7, 18)    357\n",
       "7    (8, 18)    121\n",
       "8    (9, 18)    428\n",
       "9   (10, 18)     40\n",
       "10  (11, 18)     17\n",
       "11  (12, 18)     34\n",
       "12  (13, 18)     39\n",
       "13  (14, 18)    179\n",
       "14  (15, 18)     93\n",
       "15  (16, 18)    137\n",
       "16  (17, 18)      8\n",
       "17  (18, 18)     15\n",
       "18  (19, 18)      9\n",
       "19  (20, 18)      7\n",
       "20  (21, 18)     11\n",
       "21  (22, 18)     22\n",
       "22  (23, 18)     41\n",
       "23  (24, 18)     49\n",
       "24  (25, 18)    289\n",
       "25  (26, 18)    123\n",
       "26  (27, 18)     12\n",
       "27  (28, 18)    131\n",
       "28  (29, 18)    199\n",
       "29  (30, 18)    373\n",
       "30  (31, 18)   9576\n",
       "31  (32, 18)  42459\n",
       "32  (33, 18)     59\n",
       "33  (34, 18)      4\n",
       "34  (35, 18)     88"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_shapes_of_journeys(df):\n",
    "    \"\"\"\n",
    "    Calculate and return the shapes and counts of groups in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the shapes and counts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Group by 'rid', calculate the shape of each group, and count the occurrences of each shape\n",
    "    shape_counts = df.groupby('rid').apply(lambda x: x.shape).value_counts()\n",
    "\n",
    "    # Sort the Series by the first element of the shape tuple\n",
    "    sorted_shape_counts = shape_counts.sort_index(key=lambda x: x.map(lambda y: y[0]))\n",
    "\n",
    "    # Create a DataFrame from the sorted shape counts\n",
    "    df_shape_counts = pd.DataFrame(sorted_shape_counts.items(), columns=['Shape', 'Count'])\n",
    "\n",
    "    return df_shape_counts\n",
    "\n",
    "get_shapes_of_journeys(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing y values: 53856\n",
      "\n",
      "Number of missing y values after dropping them: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>tpl</th>\n",
       "      <th>pta</th>\n",
       "      <th>ptd</th>\n",
       "      <th>wtp</th>\n",
       "      <th>arr_et</th>\n",
       "      <th>arr_wet</th>\n",
       "      <th>pass_et</th>\n",
       "      <th>dep_et</th>\n",
       "      <th>dep_wet</th>\n",
       "      <th>arr_at</th>\n",
       "      <th>pass_at</th>\n",
       "      <th>dep_at_x</th>\n",
       "      <th>cr_code</th>\n",
       "      <th>lr_code</th>\n",
       "      <th>depart_from_LDN</th>\n",
       "      <th>arrival_at_norwich</th>\n",
       "      <th>depart_from_current_station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rid, tpl, pta, ptd, wtp, arr_et, arr_wet, pass_et, dep_et, dep_wet, arr_at, pass_at, dep_at_x, cr_code, lr_code, depart_from_LDN, arrival_at_norwich, depart_from_current_station]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Number of missing y values: {len(train_dataset.loc[train_dataset['arrival_at_norwich'].isna()])}\\n\")\n",
    "\n",
    "train_dataset.dropna(subset=['arrival_at_norwich'],inplace=True) # There are a few Nan values in the y column. For now we're just dropping them \n",
    "# TODO: Fix the missing values of y \n",
    "\n",
    "print(f\"Number of missing y values after dropping them: {len(train_dataset.loc[train_dataset['arrival_at_norwich'].isna()])}\\n\")\n",
    "\n",
    "train_dataset.loc[train_dataset['arrival_at_norwich'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    31920.0\n",
       "1    31920.0\n",
       "2    31920.0\n",
       "3    31920.0\n",
       "4    31920.0\n",
       "Name: arrival_at_norwich, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Define the proportion of data to allocate to the validation set (e.g., 20%)\n",
    "validation_proportion = 0.2\n",
    "\n",
    "# Create an instance of GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=validation_proportion, random_state=42)\n",
    "\n",
    "# Get the indices for the training and validation sets\n",
    "train_idx, val_idx = next(gss.split(train_dataset, groups=train_dataset['rid']))\n",
    "\n",
    "# Create the training and validation sets\n",
    "train_set = train_dataset.iloc[train_idx]\n",
    "validation_set = train_dataset.iloc[val_idx]\n",
    "\n",
    "\n",
    "X_train = train_set[features[1:-1]]\n",
    "y_train = train_set[features[-1]]\n",
    "\n",
    "X_val = validation_set[features[1:-1]]\n",
    "y_val = validation_set[features[-1]]\n",
    "\n",
    "X_train.head(5)\n",
    "\n",
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/bgf_wq4d7pxdmbbq4nl3gqg00000gn/T/ipykernel_7374/3156949966.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  shape_counts = df.groupby('rid').apply(lambda x: x.shape).value_counts()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Shape  Count\n",
      "0    (2, 18)      3\n",
      "1    (3, 18)      4\n",
      "2    (4, 18)      6\n",
      "3    (5, 18)      5\n",
      "4    (6, 18)      9\n",
      "5    (7, 18)     12\n",
      "6    (8, 18)      2\n",
      "7    (9, 18)     21\n",
      "8   (10, 18)      5\n",
      "9   (11, 18)      8\n",
      "10  (12, 18)      6\n",
      "11  (13, 18)     19\n",
      "12  (14, 18)    137\n",
      "13  (15, 18)     41\n",
      "14  (16, 18)    108\n",
      "15  (17, 18)      8\n",
      "16  (18, 18)      9\n",
      "17  (19, 18)      4\n",
      "18  (22, 18)      6\n",
      "19  (23, 18)     16\n",
      "20  (24, 18)      3\n",
      "21  (25, 18)    128\n",
      "22  (26, 18)     30\n",
      "23  (27, 18)      2\n",
      "24  (28, 18)     77\n",
      "25  (29, 18)    115\n",
      "26  (30, 18)    289\n",
      "27  (31, 18)   7560\n",
      "28  (32, 18)  33300\n",
      "29  (33, 18)     43\n",
      "30  (34, 18)      4\n",
      "31  (35, 18)     68\n",
      "       Shape  Count\n",
      "0    (2, 18)      1\n",
      "1    (3, 18)      1\n",
      "2    (4, 18)      1\n",
      "3    (5, 18)      2\n",
      "4    (6, 18)      3\n",
      "5    (7, 18)      5\n",
      "6    (8, 18)      1\n",
      "7    (9, 18)      8\n",
      "8   (10, 18)      1\n",
      "9   (11, 18)      2\n",
      "10  (12, 18)      3\n",
      "11  (13, 18)      5\n",
      "12  (14, 18)     28\n",
      "13  (15, 18)     12\n",
      "14  (16, 18)     26\n",
      "15  (18, 18)      2\n",
      "16  (19, 18)      2\n",
      "17  (21, 18)      1\n",
      "18  (23, 18)      3\n",
      "19  (25, 18)     36\n",
      "20  (26, 18)      6\n",
      "21  (27, 18)      1\n",
      "22  (28, 18)     20\n",
      "23  (29, 18)     34\n",
      "24  (30, 18)     76\n",
      "25  (31, 18)   1904\n",
      "26  (32, 18)   8297\n",
      "27  (33, 18)     12\n",
      "28  (35, 18)     20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/bgf_wq4d7pxdmbbq4nl3gqg00000gn/T/ipykernel_7374/3156949966.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  shape_counts = df.groupby('rid').apply(lambda x: x.shape).value_counts()\n"
     ]
    }
   ],
   "source": [
    "print(get_shapes_of_journeys(train_set))\n",
    "print(get_shapes_of_journeys(validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/bgf_wq4d7pxdmbbq4nl3gqg00000gn/T/ipykernel_7374/3156949966.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  shape_counts = df.groupby('rid').apply(lambda x: x.shape).value_counts()\n",
      "/var/folders/qx/bgf_wq4d7pxdmbbq4nl3gqg00000gn/T/ipykernel_7374/3156949966.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  shape_counts = df.groupby('rid').apply(lambda x: x.shape).value_counts()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_df(df1, df2, title1, title2):\n",
    "    \"\"\"\n",
    "    Plots a comparison of two DataFrames.\n",
    "\n",
    "    Args:\n",
    "        df1 (DataFrame): The first DataFrame to plot.\n",
    "        df2 (DataFrame): The second DataFrame to plot.\n",
    "        title1 (str): The title for the first DataFrame.\n",
    "        title2 (str): The title for the second DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create a new figure\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the 'Count' column from the first DataFrame\n",
    "    ax.bar(df1['Shape'].astype(str), df1['Count'], color='b', label=title1)\n",
    "\n",
    "    # Plot the 'Count' column from the second DataFrame\n",
    "    ax.bar(df2['Shape'].astype(str), df2['Count'], color='r', label=title2)\n",
    "\n",
    "    ax.set_title('Comparison of ' + title1 + ' and ' + title2)\n",
    "    ax.set_xlabel('Shape')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_yscale('log')  # Set y-axis to logarithmic scale\n",
    "    plt.xticks(rotation=90)  # Rotate x-axis labels 90 degrees\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Automatically adjust subplot parameters to give specified padding\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "plot_df(get_shapes_of_journeys(train_set), get_shapes_of_journeys(validation_set), 'Train_set', 'Validation_set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models\n",
    "\n",
    "The commonly used metrics for scoring the performance of regression models are:\n",
    "\n",
    "- Mean Squared Error (MSE).\n",
    "\n",
    "- Root Mean Squared Error (RMSE).\n",
    "\n",
    "- Mean Absolute Error (MAE).\n",
    "\n",
    "- R2 Score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\hat{Y_i})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def mse_score(y, predictions):\n",
    "    \"\"\"\n",
    "    Calculates the mean squared error (MSE) between the true values (y) and the predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    y (array-like): The true values.\n",
    "    predictions (array-like): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    float: The mean squared error (MSE) score.\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y, predictions)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are concerned about large errors, RMSE is a good metric to use\n",
    "\n",
    "\\\n",
    "$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$\n",
    "\n",
    "\n",
    "\\\n",
    "<small>*Ogunbiyi, I. A. (2022). Top Evaluation Metrics for Regression Problems in Machine Learning. FreeCodeCamp. Retrieved from https://www.freecodecamp.org/news/evaluation-metrics-for-regression-problems-machine-learning*<small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse_score(y, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error (RMSE) between the true values (y) and the predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    y (array-like): The true values.\n",
    "    predictions (array-like): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    float: The RMSE score.\n",
    "\n",
    "    \"\"\"\n",
    "    rmse_score = np.sqrt(mean_squared_error(y, predictions))\n",
    "    return rmse_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$\n",
    "\n",
    "\\\n",
    "The model’s average absolute distance when making a prediction\n",
    "\n",
    "\\\n",
    "<small>*Ogunbiyi, I. A. (2022). Top Evaluation Metrics for Regression Problems in Machine Learning. FreeCodeCamp. Retrieved from https://www.freecodecamp.org/news/evaluation-metrics-for-regression-problems-machine-learning*<small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def score_mae(y, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Absolute Error (MAE) score between the true values (y) and the predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    y (array-like): The true values.\n",
    "    predictions (array-like): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    float: The MAE score.\n",
    "    \"\"\"\n",
    "    mae_score = mean_absolute_error(y, predictions)\n",
    "    return mae_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2 = 1 - \\frac{RSS}{TSS}$ | The coefficient of determination\n",
    "\n",
    "$RSS = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$ | The sum of squares of residuals\n",
    "\n",
    "$TSS = \\sum_{i=1}^{n} (y_i - \\bar{y})^2$ | Total sum of squares\n",
    "\n",
    "\n",
    "\\\n",
    "<small>*Ogunbiyi, I. A. (2022). Top Evaluation Metrics for Regression Problems in Machine Learning. FreeCodeCamp. Retrieved from https://www.freecodecamp.org/news/evaluation-metrics-for-regression-problems-machine-learning*<small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def score_r2(y, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the R2 score between the predicted values and the actual values.\n",
    "\n",
    "    Parameters:\n",
    "    y (array-like): The actual target values.\n",
    "    predictions (array-like): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    float: The R2 score between the predicted values and the actual values.\n",
    "    \"\"\"\n",
    "    r2score = r2_score(y, predictions)\n",
    "    \n",
    "    return r2score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "models= []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 152091418.81394377\n",
      "Validation score: 0.307134\n",
      "Iteration 2, loss = 144407618.21715006\n",
      "Validation score: 0.311864\n",
      "Iteration 3, loss = 143373378.83923426\n",
      "Validation score: 0.313951\n",
      "Iteration 4, loss = 142687074.18113124\n",
      "Validation score: 0.317665\n",
      "Iteration 5, loss = 142327880.63660181\n",
      "Validation score: 0.319965\n",
      "Iteration 6, loss = 142064492.01561481\n",
      "Validation score: 0.322001\n",
      "Iteration 7, loss = 141945125.12690508\n",
      "Validation score: 0.320883\n",
      "Iteration 8, loss = 141602117.54708177\n",
      "Validation score: 0.321483\n",
      "Iteration 9, loss = 141287633.97649527\n",
      "Validation score: 0.324049\n",
      "Iteration 10, loss = 140978119.07101578\n",
      "Validation score: 0.317304\n",
      "Iteration 11, loss = 140830783.04370466\n",
      "Validation score: 0.322714\n",
      "Iteration 12, loss = 140528068.42375326\n",
      "Validation score: 0.328887\n",
      "Iteration 13, loss = 140329422.54375216\n",
      "Validation score: 0.324023\n",
      "Iteration 14, loss = 140102868.42109421\n",
      "Validation score: 0.329739\n",
      "Iteration 15, loss = 139943703.37615043\n",
      "Validation score: 0.331630\n",
      "Iteration 16, loss = 140005052.52207366\n",
      "Validation score: 0.329990\n",
      "Iteration 17, loss = 139852668.49705002\n",
      "Validation score: 0.315754\n",
      "Iteration 18, loss = 139702780.78203836\n",
      "Validation score: 0.331146\n",
      "Iteration 19, loss = 139510709.42787018\n",
      "Validation score: 0.331341\n",
      "Iteration 20, loss = 139317345.69533160\n",
      "Validation score: 0.335416\n",
      "Iteration 21, loss = 139170422.87182337\n",
      "Validation score: 0.336427\n",
      "Iteration 22, loss = 138963957.16107634\n",
      "Validation score: 0.333470\n",
      "Iteration 23, loss = 138717773.68702173\n",
      "Validation score: 0.334863\n",
      "Iteration 24, loss = 138441309.33891332\n",
      "Validation score: 0.326840\n",
      "Iteration 25, loss = 138056721.80661160\n",
      "Validation score: 0.339685\n",
      "Iteration 26, loss = 138007320.79316649\n",
      "Validation score: 0.337600\n",
      "Iteration 27, loss = 137593782.45172790\n",
      "Validation score: 0.345082\n",
      "Iteration 28, loss = 137375781.46434146\n",
      "Validation score: 0.343730\n",
      "Iteration 29, loss = 136923099.27869558\n",
      "Validation score: 0.349391\n",
      "Iteration 30, loss = 136554240.38087955\n",
      "Validation score: 0.349402\n",
      "Iteration 31, loss = 136154345.79861286\n",
      "Validation score: 0.351451\n",
      "Iteration 32, loss = 135643917.24043071\n",
      "Validation score: 0.347466\n",
      "Iteration 33, loss = 134860577.45347160\n",
      "Validation score: 0.361889\n",
      "Iteration 34, loss = 134132001.68623483\n",
      "Validation score: 0.361162\n",
      "Iteration 35, loss = 133093679.36477616\n",
      "Validation score: 0.368709\n",
      "Iteration 36, loss = 132142184.11496818\n",
      "Validation score: 0.354982\n",
      "Iteration 37, loss = 131330761.15744202\n",
      "Validation score: 0.348295\n",
      "Iteration 38, loss = 130448517.37310030\n",
      "Validation score: 0.359894\n",
      "Iteration 39, loss = 129561704.96619368\n",
      "Validation score: 0.388864\n",
      "Iteration 40, loss = 128572710.57286112\n",
      "Validation score: 0.373503\n",
      "Iteration 41, loss = 127911135.06733336\n",
      "Validation score: 0.397285\n",
      "Iteration 42, loss = 126926293.82824726\n",
      "Validation score: 0.396817\n",
      "Iteration 43, loss = 126393368.91479911\n",
      "Validation score: 0.396081\n",
      "Iteration 44, loss = 125601617.52232945\n",
      "Validation score: 0.382145\n",
      "Iteration 45, loss = 125000370.99003121\n",
      "Validation score: 0.391278\n",
      "Iteration 46, loss = 124562955.25689954\n",
      "Validation score: 0.404528\n",
      "Iteration 47, loss = 124036815.72644071\n",
      "Validation score: 0.301754\n",
      "Iteration 48, loss = 123562329.09337208\n",
      "Validation score: 0.351854\n",
      "Iteration 49, loss = 123013914.29074758\n",
      "Validation score: 0.356889\n",
      "Iteration 50, loss = 122623257.94896320\n",
      "Validation score: 0.414803\n",
      "Iteration 51, loss = 121803590.94876616\n",
      "Validation score: 0.424596\n",
      "Iteration 52, loss = 121367130.28656583\n",
      "Validation score: 0.434624\n",
      "Iteration 53, loss = 121072564.63100168\n",
      "Validation score: 0.437389\n",
      "Iteration 54, loss = 120529686.43786430\n",
      "Validation score: 0.441246\n",
      "Iteration 55, loss = 120467407.69035463\n",
      "Validation score: 0.420388\n",
      "Iteration 56, loss = 122011527.66955471\n",
      "Validation score: 0.430460\n",
      "Iteration 57, loss = 121428252.12135231\n",
      "Validation score: 0.433056\n",
      "Iteration 58, loss = 121207312.26614249\n",
      "Validation score: 0.435924\n",
      "Iteration 59, loss = 120091945.73441635\n",
      "Validation score: 0.428178\n",
      "Iteration 60, loss = 120359492.38375179\n",
      "Validation score: 0.429594\n",
      "Iteration 61, loss = 119986539.11213553\n",
      "Validation score: 0.438680\n",
      "Iteration 62, loss = 119798531.35721630\n",
      "Validation score: 0.429545\n",
      "Iteration 63, loss = 119495679.05979210\n",
      "Validation score: 0.443269\n",
      "Iteration 64, loss = 119340239.29214545\n",
      "Validation score: 0.429918\n",
      "Iteration 65, loss = 118869849.92463985\n",
      "Validation score: 0.441830\n",
      "Iteration 66, loss = 118931588.29755361\n",
      "Validation score: 0.343521\n",
      "Iteration 67, loss = 118424621.54928663\n",
      "Validation score: 0.345137\n",
      "Iteration 68, loss = 118421843.09490809\n",
      "Validation score: 0.430195\n",
      "Iteration 69, loss = 118118636.08402783\n",
      "Validation score: 0.435385\n",
      "Iteration 70, loss = 118142794.73116742\n",
      "Validation score: 0.407707\n",
      "Iteration 71, loss = 118042862.12193418\n",
      "Validation score: 0.449455\n",
      "Iteration 72, loss = 117415212.72653924\n",
      "Validation score: 0.355995\n",
      "Iteration 73, loss = 117520428.06407897\n",
      "Validation score: 0.419896\n",
      "Iteration 74, loss = 118474998.36891419\n",
      "Validation score: 0.425930\n",
      "Iteration 75, loss = 121010948.20982145\n",
      "Validation score: 0.425642\n",
      "Iteration 76, loss = 120897474.42897876\n",
      "Validation score: 0.427682\n",
      "Iteration 77, loss = 120468555.07975334\n",
      "Validation score: 0.435518\n",
      "Iteration 78, loss = 120395846.73852877\n",
      "Validation score: 0.434314\n",
      "Iteration 79, loss = 120425593.67731221\n",
      "Validation score: 0.412331\n",
      "Iteration 80, loss = 120263439.41938144\n",
      "Validation score: 0.433411\n",
      "Iteration 81, loss = 119943484.26047455\n",
      "Validation score: 0.438074\n",
      "Iteration 82, loss = 120091184.61682829\n",
      "Validation score: 0.417121\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# mlp = MLPRegressor(hidden_layer_sizes=150,solver='sgd', max_iter=50, activation='logistic',random_state=0, learning_rate_init=0.001,verbose = 1, momentum=0.9, tol=0.001, early_stopping=True)\n",
    "\n",
    "# Define the model\n",
    "mlp = MLPRegressor(verbose = 1, early_stopping=True, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "models.append(mlp)\n",
    "\n",
    "# # Make predictions\n",
    "# mlp_pred = mlp.predict(X_val)\n",
    "\n",
    "# # Calculate the score of the predictions\n",
    "# mlp_mse_score = mean_squared_error(y_val, mlp_pred)\n",
    "\n",
    "# # Calculate RMSE\n",
    "# mlp_rmse_score = sqrt(mlp_mse_score)\n",
    "\n",
    "# print('Unfiltered Scores: ')\n",
    "# print(f\"Prediction MSE score: {mlp_mse_score}\")\n",
    "# print(f\"Prediction RMSE score: {mlp_rmse_score}\")\n",
    "# print(f\"Prediction RMSE score in seconds: {convert_seconds_to_string(mlp_rmse_score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) MLP Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# # Define the model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "# # Define the early stopping criteria\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, callbacks=[early_stopping])\n",
    "# # Evaluate the model\n",
    "# loss = model.evaluate(X_val, y_val)\n",
    "# print('Test loss:', loss)\n",
    "\n",
    "\n",
    "# mlp_results = pd.DataFrame()\n",
    "\n",
    "# mlp_results['true'] = y_val\n",
    "# mlp_results['mlp_pred'] = model.predict(X_val)\n",
    "# X_val\n",
    "# # Define the data for each column\n",
    "# data = {\n",
    "#     'tpl': [19],\n",
    "#     'depart_from_LDN': [62400],\n",
    "#     'depart_from_current_station': [62400 + 2000]\n",
    "# }\n",
    "\n",
    "# # Create the DataFrame\n",
    "# mock_data = pd.DataFrame(data, columns=features)\n",
    "\n",
    "# mock_data.drop(columns=['arrival_at_norwich','rid'],inplace=True)\n",
    "\n",
    "# mock_data\n",
    "# model.predict(mock_data)\n",
    "# mlp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) KN regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for k=1:\n",
      "R^2: 0.9808587748996705\n",
      "MAE: 430.9835226074645\n",
      "MSE: 8042961.477241919\n",
      "RMSE: 2836.011543919016\n",
      "-------------------------\n",
      "2\n",
      "Score for k=2:\n",
      "R^2: 0.9896857098150489\n",
      "MAE: 378.64587161490493\n",
      "MSE: 4333967.0364792\n",
      "RMSE: 2081.818204473964\n",
      "-------------------------\n",
      "3\n",
      "Score for k=3:\n",
      "R^2: 0.9899056464431203\n",
      "MAE: 379.5673705455312\n",
      "MSE: 4241551.748651987\n",
      "RMSE: 2059.5027916106324\n",
      "-------------------------\n",
      "4\n",
      "Score for k=4:\n",
      "R^2: 0.9899693365293835\n",
      "MAE: 390.94327800704883\n",
      "MSE: 4214789.777690755\n",
      "RMSE: 2052.9953184775545\n",
      "-------------------------\n",
      "5\n",
      "Score for k=5:\n",
      "R^2: 0.9910095880255597\n",
      "MAE: 378.8687772991535\n",
      "MSE: 3777685.952489683\n",
      "RMSE: 1943.6270096110732\n",
      "-------------------------\n",
      "6\n",
      "Score for k=6:\n",
      "R^2: 0.991376919732231\n",
      "MAE: 378.1208844172666\n",
      "MSE: 3623336.6487935656\n",
      "RMSE: 1903.5064089184375\n",
      "-------------------------\n",
      "7\n",
      "Score for k=7:\n",
      "R^2: 0.9918127549453005\n",
      "MAE: 369.97613381587837\n",
      "MSE: 3440202.8205892695\n",
      "RMSE: 1854.7783750597455\n",
      "-------------------------\n",
      "8\n",
      "Score for k=8:\n",
      "R^2: 0.99192159317114\n",
      "MAE: 369.1862065849324\n",
      "MSE: 3394470.0290312376\n",
      "RMSE: 1842.408757315064\n",
      "-------------------------\n",
      "9\n",
      "Score for k=9:\n",
      "R^2: 0.992090296416512\n",
      "MAE: 367.7356588446746\n",
      "MSE: 3323582.5233203797\n",
      "RMSE: 1823.0695333202132\n",
      "-------------------------\n",
      "10\n",
      "Score for k=10:\n",
      "R^2: 0.9922429456080812\n",
      "MAE: 365.29744856462935\n",
      "MSE: 3259440.778949905\n",
      "RMSE: 1805.3921399379983\n",
      "-------------------------\n",
      "15\n",
      "Score for k=15:\n",
      "R^2: 0.9925815611491444\n",
      "MAE: 358.2335994216345\n",
      "MSE: 3117157.7360363887\n",
      "RMSE: 1765.5474323949466\n",
      "-------------------------\n",
      "20\n",
      "Score for k=20:\n",
      "R^2: 0.9927644634105736\n",
      "MAE: 350.2833418682411\n",
      "MSE: 3040303.938274543\n",
      "RMSE: 1743.6467355156958\n",
      "-------------------------\n",
      "25\n",
      "Score for k=25:\n",
      "R^2: 0.9928828478717316\n",
      "MAE: 343.3553272886104\n",
      "MSE: 2990559.909059734\n",
      "RMSE: 1729.3235408852024\n",
      "-------------------------\n",
      "30\n",
      "Score for k=30:\n",
      "R^2: 0.9929472697213848\n",
      "MAE: 338.62793625930055\n",
      "MSE: 2963490.4580534385\n",
      "RMSE: 1721.479148306316\n",
      "-------------------------\n",
      "35\n",
      "Score for k=35:\n",
      "R^2: 0.9929624783488187\n",
      "MAE: 336.0887119748342\n",
      "MSE: 2957099.936865207\n",
      "RMSE: 1719.622033141355\n",
      "-------------------------\n",
      "40\n",
      "Score for k=40:\n",
      "R^2: 0.9929826734630063\n",
      "MAE: 333.64797270837727\n",
      "MSE: 2948614.1411761604\n",
      "RMSE: 1717.1529172371809\n",
      "-------------------------\n",
      "45\n",
      "Score for k=45:\n",
      "R^2: 0.9929829172975073\n",
      "MAE: 333.9518992680062\n",
      "MSE: 2948511.6842284948\n",
      "RMSE: 1717.1230835989873\n",
      "-------------------------\n",
      "50\n",
      "\n",
      "Model is not improving, stopping here\n",
      "\n",
      "     k       R^2         MAE           MSE         RMSE\n",
      "0    1  0.980859  430.983523  8.042961e+06  2836.011544\n",
      "1    2  0.989686  378.645872  4.333967e+06  2081.818204\n",
      "2    3  0.989906  379.567371  4.241552e+06  2059.502792\n",
      "3    4  0.989969  390.943278  4.214790e+06  2052.995318\n",
      "4    5  0.991010  378.868777  3.777686e+06  1943.627010\n",
      "5    6  0.991377  378.120884  3.623337e+06  1903.506409\n",
      "6    7  0.991813  369.976134  3.440203e+06  1854.778375\n",
      "7    8  0.991922  369.186207  3.394470e+06  1842.408757\n",
      "8    9  0.992090  367.735659  3.323583e+06  1823.069533\n",
      "9   10  0.992243  365.297449  3.259441e+06  1805.392140\n",
      "10  15  0.992582  358.233599  3.117158e+06  1765.547432\n",
      "11  20  0.992764  350.283342  3.040304e+06  1743.646736\n",
      "12  25  0.992883  343.355327  2.990560e+06  1729.323541\n",
      "13  30  0.992947  338.627936  2.963490e+06  1721.479148\n",
      "14  35  0.992962  336.088712  2.957100e+06  1719.622033\n",
      "15  40  0.992983  333.647973  2.948614e+06  1717.152917\n",
      "16  45  0.992983  333.951899  2.948512e+06  1717.123084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import warnings\n",
    "\n",
    "#ignore the Pd concat decrepit warning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "min_score = float('inf')\n",
    "knn_results = pd.DataFrame(columns=['k', 'R^2', 'MAE', 'MSE', 'RMSE'])\n",
    "\n",
    "# Initialize k to 1\n",
    "k = 1\n",
    "\n",
    "# Loop while k is less than or equal to 100\n",
    "while k <= 100:\n",
    "    # Print the current value of k\n",
    "    print(k)\n",
    "        \n",
    "    # Create a KNeighborsRegressor with k neighbors and fit it to the training data\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=k, n_jobs=-1)\n",
    "    knn_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the validation data\n",
    "    y_pred = knn_regressor.predict(X_val)\n",
    "    \n",
    "    # Calculate the mean absolute error, mean squared error, and root mean squared error\n",
    "    knn_mae = mean_absolute_error(y_val, y_pred)\n",
    "    knn_mse = mean_squared_error(y_val, y_pred)\n",
    "    knn_rmse = np.sqrt(knn_mse)  # Take the square root of the MSE to get the RMSE\n",
    "    \n",
    "    if knn_rmse <= min_score:  # Check if the current RMSE is at least 5% less than the minimum\n",
    "        min_score = knn_rmse\n",
    "    else:\n",
    "        print('\\nModel is not improving, stopping here\\n')\n",
    "        break\n",
    "        \n",
    "    print(f'Score for k={k}:')\n",
    "    print(f'R^2: {knn_regressor.score(X_val, y_val)}')\n",
    "    print(f'MAE: {knn_mae}')\n",
    "    print(f'MSE: {knn_mse}')\n",
    "    print(f'RMSE: {knn_rmse}')\n",
    "    # print(f'RMSE (in time): {convert_string_to_seconds(rmse)}')\n",
    "    print('-------------------------')\n",
    "    \n",
    "    new_row = pd.DataFrame({'k': [k], 'R^2': [knn_regressor.score(X_val, y_val)], 'MAE': [knn_mae], 'MSE': [knn_mse], 'RMSE': [knn_rmse]})\n",
    "    knn_results = pd.concat([knn_results, new_row], ignore_index=True)\n",
    "    \n",
    "        \n",
    "    # Increment k based on its current value\n",
    "    if k < 10:\n",
    "        k += 1  # Increment by 1 if k is less than 10\n",
    "    elif k <= 50:\n",
    "        k += 5  # Increment by 5 if k is less than or equal to 50\n",
    "    else:\n",
    "        k += 10  # Increment by 10 otherwise\n",
    "\n",
    "# knn_predictions = knn_regressor.predict(X_val)\n",
    "models.append(knn_regressor)\n",
    "print(knn_results)\n",
    "\n",
    "# dump(knn_regressor, '/models/knn_regressor.joblib', compress= True) \n",
    "\n",
    "# knn_regressor = load('/models/knn_regressor.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     k       R^2         MAE           MSE         RMSE\n",
      "0    1  0.980859  430.983523  8.042961e+06  2836.011544\n",
      "1    2  0.989686  378.645872  4.333967e+06  2081.818204\n",
      "2    3  0.989906  379.567371  4.241552e+06  2059.502792\n",
      "3    4  0.989969  390.943278  4.214790e+06  2052.995318\n",
      "4    5  0.991010  378.868777  3.777686e+06  1943.627010\n",
      "5    6  0.991377  378.120884  3.623337e+06  1903.506409\n",
      "6    7  0.991813  369.976134  3.440203e+06  1854.778375\n",
      "7    8  0.991922  369.186207  3.394470e+06  1842.408757\n",
      "8    9  0.992090  367.735659  3.323583e+06  1823.069533\n",
      "9   10  0.992243  365.297449  3.259441e+06  1805.392140\n",
      "10  15  0.992582  358.233599  3.117158e+06  1765.547432\n",
      "11  20  0.992764  350.283342  3.040304e+06  1743.646736\n",
      "12  25  0.992883  343.355327  2.990560e+06  1729.323541\n",
      "13  30  0.992947  338.627936  2.963490e+06  1721.479148\n",
      "14  35  0.992962  336.088712  2.957100e+06  1719.622033\n",
      "15  40  0.992983  333.647973  2.948614e+06  1717.152917\n",
      "16  45  0.992983  333.951899  2.948512e+06  1717.123084\n"
     ]
    }
   ],
   "source": [
    "print(knn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the scores against value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_KNN_Stats(stats):\n",
    "    for metric in stats:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(stats['k'], stats[metric], marker='o')\n",
    "        plt.title(f'KNN Regression model {metric} vs k')\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel(metric)\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'plots/KNN_Regression/KNN Regression model {metric} vs k.pdf')\n",
    "        plt.savefig(f'plots/KNN_Regression/KNN Regression model {metric} vs k.jpeg')\n",
    "        plt.close()\n",
    "        \n",
    "plot_KNN_Stats(knn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_estimators: 1\n",
      "RMSE :  14423.881550\n",
      "MAE :  11689.875945\n",
      "R^2 Score :  0.504871\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 2\n",
      "RMSE :  10194.480707\n",
      "MAE :  8214.249700\n",
      "R^2 Score :  0.752666\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 3\n",
      "RMSE :  7270.192730\n",
      "MAE :  5782.620130\n",
      "R^2 Score :  0.874210\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 4\n",
      "RMSE :  5271.073107\n",
      "MAE :  4084.681260\n",
      "R^2 Score :  0.933877\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 5\n",
      "RMSE :  3932.805430\n",
      "MAE :  2900.675047\n",
      "R^2 Score :  0.963191\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 6\n",
      "RMSE :  3064.765834\n",
      "MAE :  2075.270793\n",
      "R^2 Score :  0.977646\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 7\n",
      "RMSE :  2530.248765\n",
      "MAE :  1506.208446\n",
      "R^2 Score :  0.984764\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 8\n",
      "RMSE :  2219.225104\n",
      "MAE :  1115.703541\n",
      "R^2 Score :  0.988279\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 9\n",
      "RMSE :  2047.260012\n",
      "MAE :  852.227672\n",
      "R^2 Score :  0.990025\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 10\n",
      "RMSE :  1955.658498\n",
      "MAE :  677.491905\n",
      "R^2 Score :  0.990898\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 15\n",
      "RMSE :  1861.595469\n",
      "MAE :  424.721672\n",
      "R^2 Score :  0.991752\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 20\n",
      "RMSE :  1848.114642\n",
      "MAE :  405.720689\n",
      "R^2 Score :  0.991871\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 25\n",
      "RMSE :  1833.428678\n",
      "MAE :  401.357044\n",
      "R^2 Score :  0.992000\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 30\n",
      "RMSE :  1814.992326\n",
      "MAE :  399.066723\n",
      "R^2 Score :  0.992160\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 35\n",
      "RMSE :  1801.847733\n",
      "MAE :  397.325036\n",
      "R^2 Score :  0.992273\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 40\n",
      "RMSE :  1783.585265\n",
      "MAE :  395.618465\n",
      "R^2 Score :  0.992429\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 45\n",
      "RMSE :  1775.365191\n",
      "MAE :  393.974004\n",
      "R^2 Score :  0.992499\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 50\n",
      "RMSE :  1770.881199\n",
      "MAE :  392.856774\n",
      "R^2 Score :  0.992537\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 55\n",
      "RMSE :  1766.922512\n",
      "MAE :  391.254378\n",
      "R^2 Score :  0.992570\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 65\n",
      "RMSE :  1752.241861\n",
      "MAE :  388.335768\n",
      "R^2 Score :  0.992693\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 75\n",
      "RMSE :  1740.280743\n",
      "MAE :  385.322977\n",
      "R^2 Score :  0.992792\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 85\n",
      "RMSE :  1733.922944\n",
      "MAE :  383.150441\n",
      "R^2 Score :  0.992845\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 95\n",
      "RMSE :  1728.680439\n",
      "MAE :  381.605032\n",
      "R^2 Score :  0.992888\n",
      "------------------------------\n",
      "   n_estimators          RMSE           MAE        R2\n",
      "0             1  14423.881550  11689.875945  0.504871\n",
      "1             2  10194.480707   8214.249700  0.752666\n",
      "2             3   7270.192730   5782.620130  0.874210\n",
      "3             4   5271.073107   4084.681260  0.933877\n",
      "4             5   3932.805430   2900.675047  0.963191\n",
      "5             6   3064.765834   2075.270793  0.977646\n",
      "6             7   2530.248765   1506.208446  0.984764\n",
      "7             8   2219.225104   1115.703541  0.988279\n",
      "8             9   2047.260012    852.227672  0.990025\n",
      "9            10   1955.658498    677.491905  0.990898\n",
      "10           15   1861.595469    424.721672  0.991752\n",
      "11           20   1848.114642    405.720689  0.991871\n",
      "12           25   1833.428678    401.357044  0.992000\n",
      "13           30   1814.992326    399.066723  0.992160\n",
      "14           35   1801.847733    397.325036  0.992273\n",
      "15           40   1783.585265    395.618465  0.992429\n",
      "16           45   1775.365191    393.974004  0.992499\n",
      "17           50   1770.881199    392.856774  0.992537\n",
      "18           55   1766.922512    391.254378  0.992570\n",
      "19           65   1752.241861    388.335768  0.992693\n",
      "20           75   1740.280743    385.322977  0.992792\n",
      "21           85   1733.922944    383.150441  0.992845\n",
      "22           95   1728.680439    381.605032  0.992888\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xg \n",
    "\n",
    "# Initialize a DataFrame to store the results\n",
    "xgboost_reg_results = pd.DataFrame(columns=['n_estimators', 'RMSE', 'MAE', 'R2'])\n",
    "\n",
    "min_score = float('inf')\n",
    "\n",
    "n_est=1\n",
    "\n",
    "while n_est < 100:\n",
    "# for n_est in range(1,100):\n",
    "    # Instantiation \n",
    "    xgb_r = xg.XGBRegressor(objective ='reg:squarederror', n_estimators = n_est, seed = 123, n_jobs=-1) \n",
    "    \n",
    "    # Fitting the model \n",
    "    xgb_r.fit(X_train, y_train) \n",
    "    \n",
    "    # Predict the model \n",
    "    xgboost_reg_pred = xgb_r.predict(X_val) \n",
    "    \n",
    "    # RMSE Computation \n",
    "    xgboost_reg_rmse = np.sqrt(mean_squared_error(y_val, xgboost_reg_pred)) \n",
    "\n",
    "    # MAE Computation\n",
    "    xgboost_reg_mae = mean_absolute_error(y_val, xgboost_reg_pred)\n",
    "\n",
    "    # R^2 Score Computation\n",
    "    xgboost_reg_r2 = r2_score(y_val, xgboost_reg_pred)\n",
    "\n",
    "    # MSLE Computation\n",
    "    # msle = mean_squared_log_error(y_val, pred) <-- removed as throws an error eventually\n",
    "\n",
    "    print(f'\\nn_estimators: {n_est}')\n",
    "    print(\"RMSE : % f\" %(xgboost_reg_rmse))\n",
    "    print(\"MAE : % f\" %(xgboost_reg_mae))\n",
    "    print(\"R^2 Score : % f\" %(xgboost_reg_r2))\n",
    "    # print(\"MSLE : % f\" %(msle))\n",
    "    print('-' * 30)\n",
    "    \n",
    "    # Append the results to the DataFrame\n",
    "    xgboost_reg_results = pd.concat(\n",
    "        [xgboost_reg_results, \n",
    "         pd.DataFrame([{'n_estimators': n_est, 'RMSE': xgboost_reg_rmse, 'MAE': xgboost_reg_mae, 'R2': xgboost_reg_r2}])], ignore_index=True)\n",
    "\n",
    "    if knn_rmse <= min_score:  # Check if the current RMSE is at least 5% less than the minimum\n",
    "        min_score = knn_rmse\n",
    "    else:\n",
    "        print('\\nModel is not improving by at least 5%, stopping here\\n')\n",
    "        break\n",
    "\n",
    "\n",
    "    if n_est < 10:\n",
    "        n_est += 1\n",
    "    elif n_est <= 50:\n",
    "        n_est += 5\n",
    "    elif n_est <= 100:\n",
    "        n_est += 10\n",
    "    \n",
    "    \n",
    "    #     # Increment k based on its current value\n",
    "    # if k < 10:\n",
    "    #     k += 1  # Increment by 1 if k is less than 10\n",
    "    # elif k <= 50:\n",
    "    #     k += 5  # Increment by 5 if k is less than or equal to 50\n",
    "    # else:\n",
    "    #     k += 10  # Increment by 10 otherwise\n",
    "    \n",
    "models.append(xgb_r)\n",
    "\n",
    "# Display the DataFrame\n",
    "\n",
    "print(xgboost_reg_results)\n",
    "# xgb_r.save_model('/Users/joshuanewton/Desktop/temp/xgboost_model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting scores against number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_XGB_Stats(stats):\n",
    "    for metric in stats:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(stats['n_estimators'], stats[metric], marker='o')\n",
    "        plt.title(f'XGBoost Regression model {metric} vs number of estimators')\n",
    "        plt.xlabel('n_estimators')\n",
    "        plt.ylabel(metric)\n",
    "        plt.grid()\n",
    "        plt.savefig(f'plots/XGB/XGBoost Regression model {metric} vs n_estimators.jpeg')\n",
    "        plt.savefig(f'plots/XGB/XGBoost Regression model {metric} vs n_estimators.pdf')\n",
    "        plt.close()\n",
    "\n",
    "plot_XGB_Stats(xgboost_reg_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_estimators: 5\n",
      "RMSE :  1692.184531\n",
      "MAE :  322.930468\n",
      "R^2 Score :  0.993185\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 6\n",
      "RMSE :  1692.829572\n",
      "MAE :  322.482591\n",
      "R^2 Score :  0.993180\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 7\n",
      "RMSE :  1689.592844\n",
      "MAE :  322.124198\n",
      "R^2 Score :  0.993206\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 8\n",
      "RMSE :  1683.224923\n",
      "MAE :  321.827668\n",
      "R^2 Score :  0.993257\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 9\n",
      "RMSE :  1682.711353\n",
      "MAE :  321.882941\n",
      "R^2 Score :  0.993261\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 10\n",
      "RMSE :  1686.329066\n",
      "MAE :  322.128959\n",
      "R^2 Score :  0.993232\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 15\n",
      "RMSE :  1683.602038\n",
      "MAE :  322.207173\n",
      "R^2 Score :  0.993254\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 20\n",
      "RMSE :  1687.826492\n",
      "MAE :  322.431174\n",
      "R^2 Score :  0.993220\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 25\n",
      "RMSE :  1686.804586\n",
      "MAE :  322.203058\n",
      "R^2 Score :  0.993229\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 30\n",
      "RMSE :  1687.611115\n",
      "MAE :  322.333805\n",
      "R^2 Score :  0.993222\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 35\n",
      "RMSE :  1684.476610\n",
      "MAE :  322.340373\n",
      "R^2 Score :  0.993247\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 40\n",
      "RMSE :  1686.773677\n",
      "MAE :  322.307277\n",
      "R^2 Score :  0.993229\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 45\n",
      "RMSE :  1685.728727\n",
      "MAE :  322.228509\n",
      "R^2 Score :  0.993237\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 50\n",
      "RMSE :  1685.907918\n",
      "MAE :  322.188664\n",
      "R^2 Score :  0.993236\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 55\n",
      "RMSE :  1686.511211\n",
      "MAE :  322.157963\n",
      "R^2 Score :  0.993231\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 60\n",
      "RMSE :  1686.239382\n",
      "MAE :  322.203851\n",
      "R^2 Score :  0.993233\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 65\n",
      "RMSE :  1686.626674\n",
      "MAE :  322.287643\n",
      "R^2 Score :  0.993230\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 70\n",
      "RMSE :  1686.468809\n",
      "MAE :  322.261845\n",
      "R^2 Score :  0.993231\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 75\n",
      "RMSE :  1685.545268\n",
      "MAE :  322.142894\n",
      "R^2 Score :  0.993239\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 80\n",
      "RMSE :  1685.062499\n",
      "MAE :  322.109253\n",
      "R^2 Score :  0.993243\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 85\n",
      "RMSE :  1685.000436\n",
      "MAE :  322.112481\n",
      "R^2 Score :  0.993243\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 90\n",
      "RMSE :  1685.369304\n",
      "MAE :  322.149616\n",
      "R^2 Score :  0.993240\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 95\n",
      "RMSE :  1685.406213\n",
      "MAE :  322.143033\n",
      "R^2 Score :  0.993240\n",
      "------------------------------\n",
      "\n",
      "n_estimators: 100\n",
      "RMSE :  1685.108628\n",
      "MAE :  322.103318\n",
      "R^2 Score :  0.993242\n",
      "------------------------------\n",
      "   n_estimators         RMSE         MAE        R2\n",
      "0             5  1692.184531  322.930468  0.993185\n",
      "1             6  1692.829572  322.482591  0.993180\n",
      "2             7  1689.592844  322.124198  0.993206\n",
      "3             8  1683.224923  321.827668  0.993257\n",
      "4             9  1682.711353  321.882941  0.993261\n",
      "5            10  1686.329066  322.128959  0.993232\n",
      "6            15  1683.602038  322.207173  0.993254\n",
      "7            20  1687.826492  322.431174  0.993220\n",
      "8            25  1686.804586  322.203058  0.993229\n",
      "9            30  1687.611115  322.333805  0.993222\n",
      "10           35  1684.476610  322.340373  0.993247\n",
      "11           40  1686.773677  322.307277  0.993229\n",
      "12           45  1685.728727  322.228509  0.993237\n",
      "13           50  1685.907918  322.188664  0.993236\n",
      "14           55  1686.511211  322.157963  0.993231\n",
      "15           60  1686.239382  322.203851  0.993233\n",
      "16           65  1686.626674  322.287643  0.993230\n",
      "17           70  1686.468809  322.261845  0.993231\n",
      "18           75  1685.545268  322.142894  0.993239\n",
      "19           80  1685.062499  322.109253  0.993243\n",
      "20           85  1685.000436  322.112481  0.993243\n",
      "21           90  1685.369304  322.149616  0.993240\n",
      "22           95  1685.406213  322.143033  0.993240\n",
      "23          100  1685.108628  322.103318  0.993242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize a DataFrame to store the results\n",
    "rf_results = pd.DataFrame(columns=['n_estimators', 'RMSE', 'MAE', 'R2'])\n",
    "\n",
    "k=5\n",
    "\n",
    "while k <=100:\n",
    "    # Create a RandomForestRegressor object\n",
    "    rf = RandomForestRegressor(n_estimators=k, random_state=0, n_jobs=-1, verbose=0)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # dump(rf, f'/Users/joshuanewton/Desktop/temp/random_forest_{k}_trees.joblib', compress= True) \n",
    "    \n",
    "    # Predict the model \n",
    "    rf_pred = rf.predict(X_val) \n",
    "    \n",
    "    # RMSE Computation \n",
    "    rf_rmse = np.sqrt(mean_squared_error(y_val, rf_pred)) \n",
    "\n",
    "    # MAE Computation\n",
    "    rf_mae = mean_absolute_error(y_val, rf_pred)\n",
    "\n",
    "    # R^2 Score Computation\n",
    "    rf_r2 = r2_score(y_val, rf_pred)\n",
    "\n",
    "    print(f'\\nn_estimators: {k}')\n",
    "    print(\"RMSE : % f\" %(rf_rmse))\n",
    "    print(\"MAE : % f\" %(rf_mae))\n",
    "    print(\"R^2 Score : % f\" %(rf_r2))\n",
    "    print('-' * 30)\n",
    "    \n",
    "    # Append the results to the DataFrame\n",
    "    rf_results = pd.concat(\n",
    "        [rf_results, \n",
    "         pd.DataFrame([{'n_estimators': k, 'RMSE': rf_rmse, 'MAE': rf_mae, 'R2': rf_r2}])], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    if k>= 10:\n",
    "        k += 5\n",
    "    elif k >= 50:\n",
    "        k += 10\n",
    "    elif k >= 80:\n",
    "        k=100\n",
    "    else:\n",
    "        k +=1\n",
    " \n",
    " \n",
    "rf = RandomForestRegressor(n_estimators=8, random_state=0, n_jobs=-1, verbose=0)\n",
    "rf.fit(X_train, y_train)    \n",
    "\n",
    "models.append(rf)\n",
    "print(rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rf_Stats(stats):\n",
    "    for metric in stats:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(stats['n_estimators'], stats[metric], marker='o')\n",
    "        plt.title(f'Random Forest Regression model {metric} vs number of estimators')\n",
    "        plt.xlabel('n_estimators')\n",
    "        plt.ylabel(metric)\n",
    "        plt.grid()\n",
    "        plt.savefig(f'plots/RandomForest/Random Forest Regression model {metric} vs n_estimators.jpeg')\n",
    "        plt.savefig(f'plots/RandomForest/Random Forest Regression model {metric} vs n_estimators.pdf')\n",
    "        plt.close()\n",
    "\n",
    "plot_rf_Stats(rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1692.184531</td>\n",
       "      <td>322.930468</td>\n",
       "      <td>0.993185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1692.829572</td>\n",
       "      <td>322.482591</td>\n",
       "      <td>0.993180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1689.592844</td>\n",
       "      <td>322.124198</td>\n",
       "      <td>0.993206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1683.224923</td>\n",
       "      <td>321.827668</td>\n",
       "      <td>0.993257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1682.711353</td>\n",
       "      <td>321.882941</td>\n",
       "      <td>0.993261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>1686.329066</td>\n",
       "      <td>322.128959</td>\n",
       "      <td>0.993232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>1683.602038</td>\n",
       "      <td>322.207173</td>\n",
       "      <td>0.993254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>1687.826492</td>\n",
       "      <td>322.431174</td>\n",
       "      <td>0.993220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25</td>\n",
       "      <td>1686.804586</td>\n",
       "      <td>322.203058</td>\n",
       "      <td>0.993229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>1687.611115</td>\n",
       "      <td>322.333805</td>\n",
       "      <td>0.993222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35</td>\n",
       "      <td>1684.476610</td>\n",
       "      <td>322.340373</td>\n",
       "      <td>0.993247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40</td>\n",
       "      <td>1686.773677</td>\n",
       "      <td>322.307277</td>\n",
       "      <td>0.993229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45</td>\n",
       "      <td>1685.728727</td>\n",
       "      <td>322.228509</td>\n",
       "      <td>0.993237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>1685.907918</td>\n",
       "      <td>322.188664</td>\n",
       "      <td>0.993236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55</td>\n",
       "      <td>1686.511211</td>\n",
       "      <td>322.157963</td>\n",
       "      <td>0.993231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>1686.239382</td>\n",
       "      <td>322.203851</td>\n",
       "      <td>0.993233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65</td>\n",
       "      <td>1686.626674</td>\n",
       "      <td>322.287643</td>\n",
       "      <td>0.993230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>70</td>\n",
       "      <td>1686.468809</td>\n",
       "      <td>322.261845</td>\n",
       "      <td>0.993231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75</td>\n",
       "      <td>1685.545268</td>\n",
       "      <td>322.142894</td>\n",
       "      <td>0.993239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>80</td>\n",
       "      <td>1685.062499</td>\n",
       "      <td>322.109253</td>\n",
       "      <td>0.993243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85</td>\n",
       "      <td>1685.000436</td>\n",
       "      <td>322.112481</td>\n",
       "      <td>0.993243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>90</td>\n",
       "      <td>1685.369304</td>\n",
       "      <td>322.149616</td>\n",
       "      <td>0.993240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>95</td>\n",
       "      <td>1685.406213</td>\n",
       "      <td>322.143033</td>\n",
       "      <td>0.993240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>1685.108628</td>\n",
       "      <td>322.103318</td>\n",
       "      <td>0.993242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators         RMSE         MAE        R2\n",
       "0             5  1692.184531  322.930468  0.993185\n",
       "1             6  1692.829572  322.482591  0.993180\n",
       "2             7  1689.592844  322.124198  0.993206\n",
       "3             8  1683.224923  321.827668  0.993257\n",
       "4             9  1682.711353  321.882941  0.993261\n",
       "5            10  1686.329066  322.128959  0.993232\n",
       "6            15  1683.602038  322.207173  0.993254\n",
       "7            20  1687.826492  322.431174  0.993220\n",
       "8            25  1686.804586  322.203058  0.993229\n",
       "9            30  1687.611115  322.333805  0.993222\n",
       "10           35  1684.476610  322.340373  0.993247\n",
       "11           40  1686.773677  322.307277  0.993229\n",
       "12           45  1685.728727  322.228509  0.993237\n",
       "13           50  1685.907918  322.188664  0.993236\n",
       "14           55  1686.511211  322.157963  0.993231\n",
       "15           60  1686.239382  322.203851  0.993233\n",
       "16           65  1686.626674  322.287643  0.993230\n",
       "17           70  1686.468809  322.261845  0.993231\n",
       "18           75  1685.545268  322.142894  0.993239\n",
       "19           80  1685.062499  322.109253  0.993243\n",
       "20           85  1685.000436  322.112481  0.993243\n",
       "21           90  1685.369304  322.149616  0.993240\n",
       "22           95  1685.406213  322.143033  0.993240\n",
       "23          100  1685.108628  322.103318  0.993242"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression object\n",
    "LinearRegression = LinearRegression()  \n",
    "\n",
    "# Train the model using the training sets\n",
    "LinearRegression.fit(X_train, y_train)\n",
    "\n",
    "models.append(LinearRegression)\n",
    "\n",
    "# # Make predictions using the testing set\n",
    "# y_pred = regressor.predict(X_val)\n",
    "\n",
    "# # Print the coefficients\n",
    "# print('Coefficients: \\n', regressor.coef_)\n",
    "\n",
    "# # Print the mean squared error\n",
    "# print('Mean squared error: %.2f' % metrics.mean_squared_error(y_val, y_pred))\n",
    "\n",
    "# # Print the coefficient of determination: 1 is perfect prediction\n",
    "# print('Coefficient of determination: %.2f' % metrics.r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Robust Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "# Create a HuberRegressor object\n",
    "HuberRegressor = HuberRegressor()\n",
    "\n",
    "# Train the model using the training sets\n",
    "HuberRegressor.fit(X_train, y_train)\n",
    "\n",
    "models.append(HuberRegressor)\n",
    "\n",
    "# # Make predictions using the testing set\n",
    "# y_pred = regressor.predict(X_val)\n",
    "\n",
    "# # Print the coefficients\n",
    "# print('Coefficients: \\n', regressor.coef_)\n",
    "\n",
    "# # Print the mean squared error\n",
    "# print('Mean squared error: %.2f' % metrics.mean_squared_error(y_val, y_pred))\n",
    "\n",
    "# # Print the coefficient of determination: 1 is perfect prediction\n",
    "# print('Coefficient of determination: %.2f' % metrics.r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create a Lasso Regression object\n",
    "lasso = Lasso(alpha=0.1, random_state=42)\n",
    "\n",
    "# Train the model using the training sets\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "models.append(lasso)\n",
    "\n",
    "# # Make predictions using the testing set\n",
    "# y_pred = lasso.predict(X_val)\n",
    "\n",
    "# # Print the coefficients\n",
    "# print('Coefficients: \\n', lasso.coef_)\n",
    "\n",
    "# # Print the mean squared error\n",
    "# print('Mean squared error: %.2f' % metrics.mean_squared_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 20994602857132.68, NNZs: 3, Bias: 32386639980.534893, T: 1195347, Avg. loss: 1382298291093528532935983820043190272.000000\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24079854145708.25, NNZs: 3, Bias: 17451887150.448872, T: 2390694, Avg. loss: 574658356159665192079184031549227008.000000\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23006333547686.75, NNZs: 3, Bias: -27776687738.363323, T: 3586041, Avg. loss: 440576753359632296257095667160186880.000000\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7108634378557.06, NNZs: 3, Bias: -3662441744.551751, T: 4781388, Avg. loss: 371468713537858114973713201495015424.000000\n",
      "Total training time: 1.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19512999235662.66, NNZs: 3, Bias: -58873227278.528603, T: 5976735, Avg. loss: 327058148026694581234221998216839168.000000\n",
      "Total training time: 2.69 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14261261179166.69, NNZs: 3, Bias: -16329643774.386518, T: 7172082, Avg. loss: 295905992878715177862608108189122560.000000\n",
      "Total training time: 3.08 seconds.\n",
      "Convergence after 6 epochs took 3.09 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor(early_stopping=True, random_state=42, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SGDRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.SGDRegressor.html\">?<span>Documentation for SGDRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SGDRegressor(early_stopping=True, random_state=42, verbose=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SGDRegressor(early_stopping=True, random_state=42, verbose=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Create a SGDRegressor object\n",
    "sgd = SGDRegressor(max_iter=1000, tol=1e-3, verbose=1, early_stopping=True, random_state=42)\n",
    "\n",
    "# Train the model using the training sets\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "# models.append(sgd)\n",
    "\n",
    "# # Make predictions using the testing set\n",
    "# y_pred = sgd.predict(X_val)\n",
    "\n",
    "# # Print the coefficients\n",
    "# print('Coefficients: \\n', sgd.coef_)\n",
    "\n",
    "# # Print the mean squared error\n",
    "# print('Mean squared error: %.2f' % metrics.mean_squared_error(y_val, y_pred))\n",
    "\n",
    "# # Print the coefficient of determination: 1 is perfect prediction\n",
    "# print('Coefficient of determination: %.2f' % metrics.r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: MLPRegressor\n",
      "Model 2: KNeighborsRegressor\n",
      "Model 3: XGBRegressor\n",
      "Model 4: RandomForestRegressor\n",
      "Model 5: LinearRegression\n",
      "Model 6: HuberRegressor\n",
      "Model 7: Lasso\n"
     ]
    }
   ],
   "source": [
    "model_names = []\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model_name = type(model).__name__\n",
    "    model_names.append(model_name)\n",
    "    print(f\"Model {i+1}: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0.45369</td>\n",
       "      <td>7876.414635</td>\n",
       "      <td>15151.049907</td>\n",
       "      <td>229554313.277678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.992975</td>\n",
       "      <td>337.436982</td>\n",
       "      <td>1718.046845</td>\n",
       "      <td>2951684.960503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.992888</td>\n",
       "      <td>381.605032</td>\n",
       "      <td>1728.680439</td>\n",
       "      <td>2988336.06081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.993257</td>\n",
       "      <td>321.827668</td>\n",
       "      <td>1683.224923</td>\n",
       "      <td>2833246.143054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.394573</td>\n",
       "      <td>8650.629986</td>\n",
       "      <td>15949.750001</td>\n",
       "      <td>254394525.082963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>0.222805</td>\n",
       "      <td>5853.991688</td>\n",
       "      <td>18071.2504</td>\n",
       "      <td>326570091.003966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.394573</td>\n",
       "      <td>8650.630322</td>\n",
       "      <td>15949.749997</td>\n",
       "      <td>254394524.969961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Name  R2 Score Mean Absolute Error  \\\n",
       "0           MLPRegressor   0.45369         7876.414635   \n",
       "1    KNeighborsRegressor  0.992975          337.436982   \n",
       "2           XGBRegressor  0.992888          381.605032   \n",
       "3  RandomForestRegressor  0.993257          321.827668   \n",
       "4       LinearRegression  0.394573         8650.629986   \n",
       "5         HuberRegressor  0.222805         5853.991688   \n",
       "6                  Lasso  0.394573         8650.630322   \n",
       "\n",
       "  Root Mean Squared Error Mean Squared Error  \n",
       "0            15151.049907   229554313.277678  \n",
       "1             1718.046845     2951684.960503  \n",
       "2             1728.680439      2988336.06081  \n",
       "3             1683.224923     2833246.143054  \n",
       "4            15949.750001   254394525.082963  \n",
       "5              18071.2504   326570091.003966  \n",
       "6            15949.749997   254394524.969961  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the names of the metrics\n",
    "metrics_names = ['Model Name', 'R2 Score', 'Mean Absolute Error', 'Root Mean Squared Error', 'Mean Squared Error']\n",
    "\n",
    "# Function to score and record the model's metrics\n",
    "def score_and_record_model(model, X, y, model_name):\n",
    "    \"\"\"\n",
    "    Calculate the performance metrics of a regression model and record them in a pandas Series.\n",
    "\n",
    "    Parameters:\n",
    "    model (object): The trained regression model.\n",
    "    X (array-like): The input features for prediction.\n",
    "    y (array-like): The true target values.\n",
    "    model_name (str): The name of the model.\n",
    "\n",
    "    Returns:\n",
    "    metrics_series (pd.Series): A pandas Series containing the performance metrics calculated for the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    # Calculate the metrics values\n",
    "    metrics_values = [\n",
    "        model_name,\n",
    "        score_r2(y, predictions), \n",
    "        score_mae(y, predictions),\n",
    "        rmse_score(y, predictions),\n",
    "        mse_score(y, predictions)\n",
    "    ]\n",
    "    \n",
    "    # Create a series with the metrics values\n",
    "    metrics_series = pd.Series(metrics_values, index=metrics_names)\n",
    "    \n",
    "    return metrics_series\n",
    "\n",
    "# Initialize an empty DataFrame to store the model scores\n",
    "model_scores_df = pd.DataFrame(columns=metrics_names)\n",
    "\n",
    "# For each model\n",
    "for i, model in enumerate(models):\n",
    "    # Score and record the model's metrics\n",
    "    model_series = score_and_record_model(model, X_val, y_val, f'{model_names[i]}')\n",
    "    \n",
    "    # Convert the series to a DataFrame and transpose it\n",
    "    model_df = pd.DataFrame(model_series).T\n",
    "    \n",
    "    # Concatenate the model DataFrame to the scores DataFrame\n",
    "    model_scores_df = pd.concat([model_scores_df, model_df], ignore_index=True)\n",
    "    \n",
    "model_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score\n",
      "Mean Absolute Error\n",
      "Root Mean Squared Error\n",
      "Mean Squared Error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of metrics\n",
    "metrics = ['R2 Score', 'Mean Absolute Error', 'Root Mean Squared Error', 'Mean Squared Error']\n",
    "\n",
    "# Create a separate plot for each metric\n",
    "for metric in metrics:\n",
    "    \n",
    "    print(metric)\n",
    "    # Set the figure size\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Plot the metric\n",
    "    model_scores_df.plot(x='Model Name', y=metric, kind='bar')\n",
    "    \n",
    "    if metric == 'Mean Absolute Error':\n",
    "        plt.title(f'{metric} (MAE)\\n(Lower the better)')\n",
    "    elif metric == 'Root Mean Squared Error':\n",
    "        plt.title(f'{metric} (RMSE)')\n",
    "    elif metric == 'Mean Squared Error':\n",
    "        plt.title(f'{metric} (MSE)')\n",
    "    else:\n",
    "        plt.title(metric)\n",
    "        \n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=11)\n",
    "\n",
    "    # Save the plot to a file\n",
    "    plt.savefig(f\"plots/Comparison/{metric.replace(' ', '_')}.jpeg\")\n",
    "    plt.savefig(f\"plots/Comparison/{metric.replace(' ', '_')}.pdf\")\n",
    "\n",
    "    # Close the plot\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a few dummy df with fake journeys as if the user has input them in a scenario where they are delayed leaving a midway station. Add prediction time per single row. Dont forget to convert the numeric values to times. Also reference real time estimation using google maps / TrainLine current plans\n",
    "\n",
    "\n",
    "# Step one, populate Depart from LDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Load the model\n",
    "xgb_model = xgb.Booster()\n",
    "xgb_model.load_model('models/xgboost_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpl</th>\n",
       "      <th>depart_from_LDN</th>\n",
       "      <th>depart_from_current_station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>45000</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tpl  depart_from_LDN  depart_from_current_station\n",
       "0   25            45000                        63000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "London_Departing_time = '12:30'\n",
    "Ipswitch_Departing_time ='17:30' #13:39 was a real time\n",
    "\n",
    "\n",
    "\n",
    "# dummy_data = {\"tpl\" : [27,25],\n",
    "#               \"depart_from_LDN\" : [convert_string_to_seconds(London_Departing_time),convert_string_to_seconds(London_Departing_time)],\n",
    "#               \"depart_from_current_station\" : [convert_string_to_seconds(London_Departing_time), convert_string_to_seconds(Ipswitch_Departing_time)]}\n",
    "\n",
    "dummy_data = {\"tpl\" : [25],\n",
    "              \"depart_from_LDN\" : [convert_string_to_seconds(London_Departing_time)],\n",
    "              \"depart_from_current_station\" : [convert_string_to_seconds(Ipswitch_Departing_time)]}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dummy_data)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
